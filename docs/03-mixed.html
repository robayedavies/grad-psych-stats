<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Psychological data analysis for graduate students - 5&nbsp; Developing linear mixed-effects models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-glmm.html" rel="next">
<link href="./02-mixed.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Developing linear mixed-effects models</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Psychological data analysis for graduate students</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">MAKING THE MOST OF R</span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./knowledge-ecosystem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">R knowledge</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./visualization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data visualization</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">MODELS</span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-multilevel.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to multilevel data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-mixed.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction to linear mixed-effects models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-mixed.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Developing linear mixed-effects models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-glmm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to Generalized Linear Mixed-effects Models</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">WRITING ABOUT RESEARCH</span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction: the why</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./what.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">What</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./how.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">How</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">END</span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-dev-mixed-motivations" id="toc-sec-dev-mixed-motivations" class="nav-link active" data-scroll-target="#sec-dev-mixed-motivations"><span class="toc-section-number">5.1</span>  Motivations: to grow in sophistication</a></li>
  <li><a href="#sec-dev-mixed-ideas" id="toc-sec-dev-mixed-ideas" class="nav-link" data-scroll-target="#sec-dev-mixed-ideas"><span class="toc-section-number">5.2</span>  The key idea to get us started</a></li>
  <li><a href="#sec-dev-mixed-targets" id="toc-sec-dev-mixed-targets" class="nav-link" data-scroll-target="#sec-dev-mixed-targets"><span class="toc-section-number">5.3</span>  Targets</a></li>
  <li><a href="#sec-dev-mixed-guide" id="toc-sec-dev-mixed-guide" class="nav-link" data-scroll-target="#sec-dev-mixed-guide"><span class="toc-section-number">5.4</span>  Study guide</a></li>
  <li><a href="#sec-dev-mixed-data" id="toc-sec-dev-mixed-data" class="nav-link" data-scroll-target="#sec-dev-mixed-data"><span class="toc-section-number">5.5</span>  The data we will work with: ML word recognition study</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-hypotheses" id="toc-sec-dev-mixed-hypotheses" class="nav-link" data-scroll-target="#sec-dev-mixed-hypotheses"><span class="toc-section-number">5.5.1</span>  Research hypotheses</a></li>
  <li><a href="#sec-dev-mixed-data-variables" id="toc-sec-dev-mixed-data-variables" class="nav-link" data-scroll-target="#sec-dev-mixed-data-variables"><span class="toc-section-number">5.5.2</span>  The ML recognition study data variables</a></li>
  <li><a href="#sec-dev-mixed-data-download" id="toc-sec-dev-mixed-data-download" class="nav-link" data-scroll-target="#sec-dev-mixed-data-download"><span class="toc-section-number">5.5.3</span>  Locate and download the data file</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-tidy" id="toc-sec-dev-mixed-tidy" class="nav-link" data-scroll-target="#sec-dev-mixed-tidy"><span class="toc-section-number">5.6</span>  Tidy the data</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-import" id="toc-sec-dev-mixed-import" class="nav-link" data-scroll-target="#sec-dev-mixed-import"><span class="toc-section-number">5.6.1</span>  Read-in the data file using the read_csv() function</a></li>
  <li><a href="#sec-dev-mixed-EDA" id="toc-sec-dev-mixed-EDA" class="nav-link" data-scroll-target="#sec-dev-mixed-EDA"><span class="toc-section-number">5.6.2</span>  Examine the distribution of raw RT data using density plots</a></li>
  <li><a href="#sec-dev-mixed-data-filter" id="toc-sec-dev-mixed-data-filter" class="nav-link" data-scroll-target="#sec-dev-mixed-data-filter"><span class="toc-section-number">5.6.3</span>  Filter observations</a></li>
  <li><a href="#sec-dev-mixed-data-transform" id="toc-sec-dev-mixed-data-transform" class="nav-link" data-scroll-target="#sec-dev-mixed-data-transform"><span class="toc-section-number">5.6.4</span>  Select or transform the variables: the log10 transformation of RT</a></li>
  <li><a href="#sec-dev-mixed-data-tidy-conclusions" id="toc-sec-dev-mixed-data-tidy-conclusions" class="nav-link" data-scroll-target="#sec-dev-mixed-data-tidy-conclusions"><span class="toc-section-number">5.6.5</span>  Data tidying – conclusions</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-crossed-random" id="toc-sec-dev-mixed-crossed-random" class="nav-link" data-scroll-target="#sec-dev-mixed-crossed-random"><span class="toc-section-number">5.7</span>  Repeated measures designs and crossed random effects</a></li>
  <li><a href="#sec-dev-mixed-working-lme" id="toc-sec-dev-mixed-working-lme" class="nav-link" data-scroll-target="#sec-dev-mixed-working-lme"><span class="toc-section-number">5.8</span>  Working with mixed-effects models</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-viz-facetting" id="toc-sec-dev-mixed-viz-facetting" class="nav-link" data-scroll-target="#sec-dev-mixed-viz-facetting"><span class="toc-section-number">5.8.1</span>  Use facetting in ggplot to examine data by person</a></li>
  <li><a href="#sec-dev-mixed-complete-pooling" id="toc-sec-dev-mixed-complete-pooling" class="nav-link" data-scroll-target="#sec-dev-mixed-complete-pooling"><span class="toc-section-number">5.8.2</span>  Approximations to Linear Mixed-effects models: complete pooling</a></li>
  <li><a href="#sec-dev-mixed-no-pooling" id="toc-sec-dev-mixed-no-pooling" class="nav-link" data-scroll-target="#sec-dev-mixed-no-pooling"><span class="toc-section-number">5.8.3</span>  Approximations to Linear Mixed-effects models: no pooling</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-lme" id="toc-sec-dev-mixed-lme" class="nav-link" data-scroll-target="#sec-dev-mixed-lme"><span class="toc-section-number">5.9</span>  The linear mixed-effects model</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-fixed-random" id="toc-sec-dev-mixed-fixed-random" class="nav-link" data-scroll-target="#sec-dev-mixed-fixed-random"><span class="toc-section-number">5.9.1</span>  Fixed and random effects</a></li>
  <li><a href="#sec-dev-mixed-variance-covariance" id="toc-sec-dev-mixed-variance-covariance" class="nav-link" data-scroll-target="#sec-dev-mixed-variance-covariance"><span class="toc-section-number">5.9.2</span>  Variance and covariance</a></li>
  <li><a href="#sec-dev-mixed-random-stimulus-effects" id="toc-sec-dev-mixed-random-stimulus-effects" class="nav-link" data-scroll-target="#sec-dev-mixed-random-stimulus-effects"><span class="toc-section-number">5.9.3</span>  Random effects of differences between stimuli</a></li>
  <li><a href="#sec-dev-mixed-random-participants-stimuli" id="toc-sec-dev-mixed-random-participants-stimuli" class="nav-link" data-scroll-target="#sec-dev-mixed-random-participants-stimuli"><span class="toc-section-number">5.9.4</span>  A model including random effects of differences between stimuli as well as participants</a></li>
  <li><a href="#sec-dev-mixed-lmer" id="toc-sec-dev-mixed-lmer" class="nav-link" data-scroll-target="#sec-dev-mixed-lmer"><span class="toc-section-number">5.9.5</span>  Fitting a mixed-effect model using lmer()</a></li>
  <li><a href="#sec-dev-mixed-lmer-results" id="toc-sec-dev-mixed-lmer-results" class="nav-link" data-scroll-target="#sec-dev-mixed-lmer-results"><span class="toc-section-number">5.9.6</span>  Reading the lmer() results</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-regularisation" id="toc-sec-dev-mixed-regularisation" class="nav-link" data-scroll-target="#sec-dev-mixed-regularisation"><span class="toc-section-number">5.10</span>  Mixed-effects models, partial pooling, and shrinkage or regularisation of estimates</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-overfitting" id="toc-sec-dev-mixed-overfitting" class="nav-link" data-scroll-target="#sec-dev-mixed-overfitting"><span class="toc-section-number">5.10.1</span>  Overfitting</a></li>
  <li><a href="#sec-dev-mixed-partial-pooling" id="toc-sec-dev-mixed-partial-pooling" class="nav-link" data-scroll-target="#sec-dev-mixed-partial-pooling"><span class="toc-section-number">5.10.2</span>  Partial pooling: shrinkage or borrowing strength</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-estimation" id="toc-sec-dev-mixed-estimation" class="nav-link" data-scroll-target="#sec-dev-mixed-estimation"><span class="toc-section-number">5.11</span>  Estimation methods – An intuitive account of estimation in mixed-effects models</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-convergence-problems" id="toc-sec-dev-mixed-convergence-problems" class="nav-link" data-scroll-target="#sec-dev-mixed-convergence-problems"><span class="toc-section-number">5.11.1</span>  Convergence problems</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-evaluating" id="toc-sec-dev-mixed-evaluating" class="nav-link" data-scroll-target="#sec-dev-mixed-evaluating"><span class="toc-section-number">5.12</span>  Fitting and evaluating Linear Mixed-effects models</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-model-comparison" id="toc-sec-dev-mixed-model-comparison" class="nav-link" data-scroll-target="#sec-dev-mixed-model-comparison"><span class="toc-section-number">5.12.1</span>  Model comparison approach</a></li>
  <li><a href="#sec-dev-mixed-IC" id="toc-sec-dev-mixed-IC" class="nav-link" data-scroll-target="#sec-dev-mixed-IC"><span class="toc-section-number">5.12.2</span>  Model comparison using information criteria, AIC and BIC</a></li>
  <li><a href="#sec-dev-mixed-LRT" id="toc-sec-dev-mixed-LRT" class="nav-link" data-scroll-target="#sec-dev-mixed-LRT"><span class="toc-section-number">5.12.3</span>  Model comparison using the Likelihood Ratio Test</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-model-steps" id="toc-sec-dev-mixed-model-steps" class="nav-link" data-scroll-target="#sec-dev-mixed-model-steps"><span class="toc-section-number">5.13</span>  Modeling steps recommendations</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-REML" id="toc-sec-dev-mixed-REML" class="nav-link" data-scroll-target="#sec-dev-mixed-REML"><span class="toc-section-number">5.13.1</span>  Maximum Likelihood and Restricted Maximum Likelihood</a></li>
  <li><a href="#sec-dev-mixed-anova" id="toc-sec-dev-mixed-anova" class="nav-link" data-scroll-target="#sec-dev-mixed-anova"><span class="toc-section-number">5.13.2</span>  Comparing models of varying random effects but constant fixed effects</a></li>
  <li><a href="#sec-dev-mixed-evaluate-random-effects" id="toc-sec-dev-mixed-evaluate-random-effects" class="nav-link" data-scroll-target="#sec-dev-mixed-evaluate-random-effects"><span class="toc-section-number">5.13.3</span>  Evaluating random effects of subjects or items on slopes</a></li>
  <li><a href="#sec-dev-mixed-discussion-p-values" id="toc-sec-dev-mixed-discussion-p-values" class="nav-link" data-scroll-target="#sec-dev-mixed-discussion-p-values"><span class="toc-section-number">5.13.4</span>  Effects estimates and <em>significance</em> or p-values</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-reporting-results" id="toc-sec-dev-mixed-reporting-results" class="nav-link" data-scroll-target="#sec-dev-mixed-reporting-results"><span class="toc-section-number">5.14</span>  Reporting results</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-reporting-comparisons" id="toc-sec-dev-mixed-reporting-comparisons" class="nav-link" data-scroll-target="#sec-dev-mixed-reporting-comparisons"><span class="toc-section-number">5.14.1</span>  Reporting comparisons of ML and REML models</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-summary" id="toc-sec-dev-mixed-summary" class="nav-link" data-scroll-target="#sec-dev-mixed-summary"><span class="toc-section-number">5.15</span>  Summary</a>
  <ul class="collapse">
  <li><a href="#sec-dev-mixed-glossary-useful-functions" id="toc-sec-dev-mixed-glossary-useful-functions" class="nav-link" data-scroll-target="#sec-dev-mixed-glossary-useful-functions"><span class="toc-section-number">5.15.1</span>  Glossary: useful functions</a></li>
  </ul></li>
  <li><a href="#sec-dev-mixed-recommended-reading" id="toc-sec-dev-mixed-recommended-reading" class="nav-link" data-scroll-target="#sec-dev-mixed-recommended-reading"><span class="toc-section-number">5.16</span>  Recommended reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-dev-mixed" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Developing linear mixed-effects models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<div class="cell">

</div>
<section id="sec-dev-mixed-motivations" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-dev-mixed-motivations"><span class="header-section-number">5.1</span> Motivations: to grow in sophistication</h2>
<p>Linear mixed-effects models are important, interesting, and sometimes challenging. We have worked through two chapters (see <a href="01-multilevel.html"><span>Chapter&nbsp;3</span></a>, <a href="02-mixed.html"><span>Chapter&nbsp;4</span></a>) in which we have aimed to learn:</p>
<ul>
<li><strong>To recognize</strong> the situations where we shall see multilevel structured data and therefore where we will need to apply multilevel or mixed-effects models.</li>
<li><strong>To understand</strong> the nature and the advantages of these models: what they are, and why they work better than other kinds of models, given multilevel data.</li>
<li><strong>To practice</strong> how we code for mixed-effects models, and how we read or write about the results.</li>
</ul>
<p>We now need to develop our understanding and skills further. And we now need to examine some of the complexities that we may face when we work with mixed-effects models.</p>
<p>Our approach will continue to depend on verbal explanation, visualization and a practical code-based approach to the modeling.</p>
</section>
<section id="sec-dev-mixed-ideas" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-dev-mixed-ideas"><span class="header-section-number">5.2</span> The key idea to get us started</h2>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Shrinkage or regularization means that models of data should be excited by the data but <em>not too</em> excited.</p>
</div>
</div>
<p>This means our models work better <em>if</em> they are informed by all the data, and take into account random differences but also <em>if</em> they are not too strongly influenced by individual (participant or item) data.</p>
</section>
<section id="sec-dev-mixed-targets" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="sec-dev-mixed-targets"><span class="header-section-number">5.3</span> Targets</h2>
<p>We are probably now at a stage, in the development of our skills and understanding, where we can be more specific about our targets for learning: what capacities or abilities we want to have by the time we complete the course. I have held back specifying the targets in this way because, first, we had to learn the basic vocabulary. Now that we have done that, we can lay out the targets against which we can assess the progression of our learning.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>We have three capacities we seek to develop. These include the capacity:</p>
<ol type="1">
<li>to understand mixed-effects models;</li>
<li>to work with these models practically or efficiently in R;</li>
<li>and to communicate their results effectively (to ourselves and others).</li>
</ol>
</div>
</div>
<p>We should be aware that the development of skills and understanding in relation to each of these capacities will travel at different speeds for different people, and <em>within any person</em> at different speeds for different capacities.</p>
<p>We should also be aware that our internal evaluation of our understanding will not exactly match the evaluation that comes from external assessment. In other words, we might not be satisfied with our understanding but, still, our understanding might be satisfactory. It might be that we can learn to say in words what mixed-effects models are or involve, or what their results mean, <em>very effectively</em> even if we remain unsure about our understanding.</p>
<p>For these reasons, I specify what we are aiming to develop in terms of what we can <em>do</em>. You can test your development against this checklist of targets for learning.</p>
<ol type="1">
<li>We want to develop the capacity to <strong>understand</strong> mixed-effects models, the capacity to:</li>
</ol>
<ul>
<li>recognize where data have a multilevel structure;</li>
<li>recognize where multilevel or mixed-effects models are required;</li>
<li>distinguish the elements of a mixed-effects model, including fixed effects and random effects;</li>
<li>explain how random effects can be understood in terms of random differences (or deviations) between groups or classes or individuals, in intercepts or slopes;</li>
<li>explain how random effects can be understood in terms of variances, as a means to account for random differences between groups or classes or individuals in intercepts or slopes;</li>
<li>explain how mixed-effects models work better than linear models, for multilevel structured data;</li>
<li>explain how mixed-effects models work better because they allow partial-pooling of estimates.</li>
</ul>
<ol start="2" type="1">
<li>We want to develop the capacity to <strong>work practically</strong> with mixed-effects models in R, the capacity to:</li>
</ol>
<ul>
<li>specify a mixed-effects model in <code>lmer()</code> code;</li>
<li>identify how the mixed-effects model code varies, depending on the kinds of random effects that are assumed;</li>
<li>identify the elements of the output or results that come from an <code>lmer()</code> mixed-effects analysis;</li>
<li>interpret the fixed-effects estimates;</li>
<li>interpret the random effects estimates, including both the variance and covariance estimates.</li>
</ul>
<ol start="3" type="1">
<li>We want to develop the capacity to <strong>communicate</strong> the results of mixed-effects models effectively, to ourselves and to others, the capacity to:</li>
</ol>
<ul>
<li>describe in words and summary tables the results of a mixed-effects model;</li>
<li>visualize the effects estimates or predictions from a mixed-effects model.</li>
</ul>
</section>
<section id="sec-dev-mixed-guide" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec-dev-mixed-guide"><span class="header-section-number">5.4</span> Study guide</h2>
<p>I have provided a collection of materials you can use. Here, I explain what they are and how I suggest you use them.</p>
<p><strong>1. Video recordings of lectures</strong></p>
<p>1.1. I have recorded a lecture in three parts. The lectures should be accessible by anyone who has the link.</p>
<ul>
<li><a href="https://dtu-panopto.lancs.ac.uk/Panopto/Pages/Viewer.aspx?id=6ee1618c-ced2-425b-9213-ace4011ea856">Part 1</a> – about 13 minutes</li>
<li><a href="https://dtu-panopto.lancs.ac.uk/Panopto/Pages/Viewer.aspx?id=01dccf63-8b1e-406c-8694-ace401229f10">Part 2</a> – about 13 minutes</li>
<li><a href="https://dtu-panopto.lancs.ac.uk/Panopto/Pages/Viewer.aspx?id=ddde4efb-2975-4347-b255-ace401328b39">Part 3</a> – about 24 minutes</li>
</ul>
<p>1.2. I suggest you watch the recordings then read the rest of this chapter. The lectures provide a summary of the main points.</p>
<p><strong>2. Chapter: 03-mixed</strong></p>
<p>2.1. I have written this chapter to discuss the main ideas and set out the practical steps you can follow to start to develop the skills required to analyse multilevel structured data with crossed random effects.</p>
<p>2.2. The practical elements include data tidying, visualization and analysis steps.</p>
<p>2.3. You can read the chapter, run the code, and do the exercises.</p>
<ul>
<li>Read in the example <strong>ML word recognition study</strong> dataset.</li>
<li>Edit example code to create alternate visualizations of variable distributions and of the relationships between critical variables.</li>
<li>Experiment with the .R code used to work with the example data.</li>
<li>Run linear mixed-effects models of demonstration data.</li>
<li>Run linear mixed-effects models of alternate data sets.</li>
<li>Review the recommended readings (<a href="#sec-dev-mixed-recommended-reading"><span>Section&nbsp;5.16</span></a>).</li>
</ul>
<p><strong>3. Practical workbook materials</strong></p>
<p>3.1 In the following sections, I describe the practical steps, and associated resources, you can use for your learning.</p>
</section>
<section id="sec-dev-mixed-data" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec-dev-mixed-data"><span class="header-section-number">5.5</span> The data we will work with: ML word recognition study</h2>
<p>In this chapter, we will be working with the <strong>ML word recognition study</strong> dataset. ML examined <em>visual</em> word recognition in younger and older adults using the lexical decision task.</p>
<p>In lexical decision, participants are presented with a stimulus: a string of letters that is either a real word (e.g., ‘car’) or a made-up or non-word (e.g., ‘cas’). Participants are required to respond to the stimulus by pressing a button to indicate either that they think the stimulus is a word or that they think it is a non-word. Each complete sequence of events, in which a stimulus is presented and a response is recorded, is known as a <em>trial</em>. In the lexical decision task implemented by ML, all study participants were presented with a mix of 160 word stimuli and 160 non-word stimuli, in random order, in a total of 320 trials.</p>
<p>Each stimulus was presented one at a time on the computer screen. The critical outcome measure was the reaction time (RT) or latency for each response. Observed RT represents the interval of time from the moment the stimulus was first presented (the stimulus onset) to the moment the response was made (the response onset).</p>
<p>Lexical decision is a very popular technique for examining word recognition, especially in adults. While not every graduate student will be interested in word recognition, or reading, everyone should understand that tasks like lexical decision are similar to a range of other tasks used in experimental psychological science.</p>
<p>The critical feature of the study, here, is that we have an outcome – a decision response – observed multiple times (for each stimulus) for each participant. We shall be analyzing the speed of response, reaction time (RT), measured in milliseconds (ms).</p>
<p>In our analyses, the focus of our interest will be on the ways in which participant attributes (like age) or word properties (like frequency) influence the speed of response in a task designed measure the ability to recognize visually presented English words. In analyzing the effects of participant attributes on recognition response RTs, we will use data – about those attributes – that were recorded using a mix of survey questions (about age, etc.) and standardized ability tests that were administered to study participants alongside the lexical decision task.</p>
<p>The total number of participants for this study was 39, including a group of younger adults and a group of older adults. Information was collected about the participants’ age, education and gender. In addition, participants were asked to complete ability measures (TOWRE sight word and phonemic tests, <span class="citation" data-cites="torgesen1999towre">Torgesen et al. (<a href="references.html#ref-torgesen1999towre" role="doc-biblioref">1999</a>)</span>) and a measure of reading experience (Author Recognition Test, ART, <span class="citation" data-cites="Masterson2007c">Masterson &amp; Hayes (<a href="references.html#ref-Masterson2007c" role="doc-biblioref">2007</a>)</span>).</p>
<section id="sec-dev-mixed-hypotheses" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="sec-dev-mixed-hypotheses"><span class="header-section-number">5.5.1</span> Research hypotheses</h3>
<p>Instead of posing a simple and general research question, we shall orient our work around a set of quite specific predictions. ML hypothesized:</p>
<ol type="1">
<li>Effects of stimulus attributes</li>
</ol>
<ul>
<li>Predicting that words that are shorter, that look like more other words, and that appear frequently in the language will be easier to recognize.</li>
</ul>
<ol start="2" type="1">
<li>Effects of participant attributes</li>
</ol>
<ul>
<li>Predicting that older readers would be faster and more accurate than younger readers in word recognition.</li>
</ul>
<ol start="3" type="1">
<li>Effects of interactions between the effects of word attributes and person attributes.</li>
</ol>
<ul>
<li>Predicting that better (older) readers will show smaller effects of word attributes.</li>
</ul>
<p>In this chapter, we can focus on one specific prediction as we work through the practical steps of conducting an analysis using linear mixed-effects models.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Research hypothesis: Words that are shorter, that look like more other words, and that appear frequently in the language will be easier to recognize.</li>
</ul>
</div>
</div>
</section>
<section id="sec-dev-mixed-data-variables" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="sec-dev-mixed-data-variables"><span class="header-section-number">5.5.2</span> The ML recognition study data variables</h3>
<p>In summary, ML collected data on lexical decision task response reaction times (RTs) and accuracy and information on participants, including age, reading ability and reading experience. In addition, she collected information on the properties of the lexical decision stimulus items, including variables like the length or frequency of words (values taken from the English Lexicon Project, <span class="citation" data-cites="Balota2007">Balota et al. (<a href="references.html#ref-Balota2007" role="doc-biblioref">2007</a>)</span>).</p>
<p>The ML study data includes the following variables that we will work with (as well as some you can ignore):</p>
<ol type="1">
<li>Identifying variables</li>
</ol>
<ul>
<li><code>subjectID</code> – identifying code for participants</li>
<li><code>item_name</code> – words presented as stimuli</li>
<li><code>item_number</code> – identifying code for words presented</li>
</ul>
<ol start="2" type="1">
<li>Response variables</li>
</ol>
<ul>
<li><code>RT</code> – response reaction time (ms), for responses to words</li>
</ul>
<ol start="3" type="1">
<li>Participant attribute variables</li>
</ol>
<ul>
<li><code>Age</code> – in years</li>
<li><code>Gender</code> – coded M (male), F (female)</li>
<li><code>TOWRE_wordacc</code> – word reading skill, words read correctly (out of 104)</li>
<li><code>TOWRE_nonwordacc</code> – nonword reading skill, nonwords (made up words) read correctly (out of 63)</li>
<li><code>ART_HRminusFR</code> – reading experience score</li>
</ul>
<ol start="4" type="1">
<li>Stimulus property variables</li>
</ol>
<ul>
<li><code>Length</code> – word length, in letters</li>
<li><code>Ortho_N</code> – orthographic neighbourhood size, how many other words in English a stimulus word looks like</li>
<li><code>OLD</code> – orthographic Levenshtein distance, how many letter edits (addition, deletion or substitution) it would take to make a stimulus word look like another English word (a measure of orthographic neighbourhood) <span class="citation" data-cites="Yarkoni2008b">(<a href="references.html#ref-Yarkoni2008b" role="doc-biblioref">Yarkoni et al., 2008</a>)</span></li>
<li><code>BG_Sum, BG_Mean, BG_Freq_By_Pos</code> – measures of how common are pairs of letters that compose stimulus words</li>
<li><code>SUBTLWF, LgSUBTLWF, SUBTLCD, LgSUBTLCD</code> – measures of how common stimulus words are, taken from the SUBTLEX corpus analysis of word frequency <span class="citation" data-cites="Brysbaert2009a">(<a href="references.html#ref-Brysbaert2009a" role="doc-biblioref">Brysbaert &amp; New, 2009</a>)</span></li>
</ul>
</section>
<section id="sec-dev-mixed-data-download" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="sec-dev-mixed-data-download"><span class="header-section-number">5.5.3</span> Locate and download the data file</h3>
<p>You can download the <a href="files/data-03-mixed.zip">data-03-mixed.zip</a> files folder to get the data you need for the practical work we will be doing for this chapter.</p>
<p>The data are held in one file:</p>
<ul>
<li><code>subjects.behaviour.words-310114.csv</code> which holds information about the (word) stimuli, participants, and the responses recorded in the ML study.</li>
</ul>
<p>The <code>.csv</code> file is a <em>comma separated values</em> file and can be opened in Excel.</p>
<p>The data file is collected together with the .R scripts:</p>
<ul>
<li><code>03-mixed-workbook.R</code> the workbook you will need to do the practical exercises.</li>
<li><code>03-mixed-workbook-answers.R</code> with answers to questions and code for exercises.</li>
</ul>
</section>
</section>
<section id="sec-dev-mixed-tidy" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="sec-dev-mixed-tidy"><span class="header-section-number">5.6</span> Tidy the data</h2>
<p>In <a href="02-mixed.html#sec-intro-mixed-tidy-data"><span>Section&nbsp;4.7</span></a>, we saw how we may need to tidy the data we collect in experimental studies: combining data about responses with data about participant attributes or stimulus properties, and restructuring the data so that they are in a tidy format. For this class, many steps in the process of data tidying were completed previously. Thus, we only need to perform steps 1, 3 and 4 of the usual <em>data tidying</em> process:</p>
<ol type="1">
<li>Import the data or read the data into R, see <a href="#sec-dev-mixed-import"><span>Section&nbsp;5.6.1</span></a>;</li>
<li>Restructure the data;</li>
<li>Select or transform variables, see <a href="#sec-dev-mixed-data-transform"><span>Section&nbsp;5.6.4</span></a>;</li>
<li>Filter observations, see <a href="#sec-dev-mixed-data-filter"><span>Section&nbsp;5.6.3</span></a>.</li>
</ol>
<p>We are going to first filter the observations, then transform the outcome variable. We will explain why we have to do this as we proceed.</p>
<p>We will use <code>tidyverse</code> library functions to do this work, as usual.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="sec-dev-mixed-import" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="sec-dev-mixed-import"><span class="header-section-number">5.6.1</span> Read-in the data file using the read_csv() function</h3>
<p>I am going to assume you have downloaded the data file, and that you know where it is. We use <code>read_csv</code> to read one file into R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>ML.all <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"subjects.behaviour.words-310114.csv"</span>, <span class="at">na =</span> <span class="st">"-999"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The data file <code>subjects.behaviour.words-310114.csv</code> holds all the data about everything (behaviour, participants, stimuli) we need for our analysis wor.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is <em>always</em> a good idea to first inspect what you have got when you read a data file into R before you do anything more demanding.</p>
<ul>
<li>You <strong>cannot assume</strong> that the data are what you think they are</li>
<li>or that the data are structured or coded in the ways that you think (or have been told) they should be structured or coded.</li>
</ul>
</div>
</div>
<p>You can inspect the first few rows of the dataset using <code>head()</code>.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning in subjectID == c("GB9", "NH1", "A15", "B18"): longer object length is
not a multiple of shorter object length</code></pre>
</div>
<div class="cell-output-display">

<table class="table" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:right;"> item_number </th>
   <th style="text-align:left;"> subjectID </th>
   <th style="text-align:left;"> Test </th>
   <th style="text-align:right;"> Age </th>
   <th style="text-align:right;"> Years_in_education </th>
   <th style="text-align:left;"> Gender </th>
   <th style="text-align:right;"> TOWRE_wordacc </th>
   <th style="text-align:right;"> TOWRE_nonwordacc </th>
   <th style="text-align:right;"> ART_HRminusFR </th>
   <th style="text-align:right;"> RT </th>
   <th style="text-align:right;"> COT </th>
   <th style="text-align:left;"> Subject </th>
   <th style="text-align:right;"> Trial.order </th>
   <th style="text-align:left;"> item_name </th>
   <th style="text-align:right;"> Length </th>
   <th style="text-align:right;"> Ortho_N </th>
   <th style="text-align:right;"> BG_Sum </th>
   <th style="text-align:right;"> BG_Mean </th>
   <th style="text-align:right;"> BG_Freq_By_Pos </th>
   <th style="text-align:left;"> item_type </th>
   <th style="text-align:right;"> SUBTLWF </th>
   <th style="text-align:right;"> LgSUBTLWF </th>
   <th style="text-align:right;"> SUBTLCD </th>
   <th style="text-align:right;"> LgSUBTLCD </th>
   <th style="text-align:right;"> OLD </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:left;"> GB9 </td>
   <td style="text-align:left;"> ALT </td>
   <td style="text-align:right;"> 21 </td>
   <td style="text-align:right;"> 11 </td>
   <td style="text-align:left;"> F </td>
   <td style="text-align:right;"> 78 </td>
   <td style="text-align:right;"> 41 </td>
   <td style="text-align:right;"> 18 </td>
   <td style="text-align:right;"> 368.66 </td>
   <td style="text-align:right;"> 134057.8 </td>
   <td style="text-align:left;"> GB9 </td>
   <td style="text-align:right;"> 54 </td>
   <td style="text-align:left;"> went </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 249 </td>
   <td style="text-align:right;"> 198 </td>
   <td style="text-align:right;"> 29 </td>
   <td style="text-align:left;"> word </td>
   <td style="text-align:right;"> 411.51 </td>
   <td style="text-align:right;"> 4.322 </td>
   <td style="text-align:right;"> 79.6 </td>
   <td style="text-align:right;"> 3.825 </td>
   <td style="text-align:right;"> 1.2 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:left;"> NH1 </td>
   <td style="text-align:left;"> TAL </td>
   <td style="text-align:right;"> 52 </td>
   <td style="text-align:right;"> 18 </td>
   <td style="text-align:left;"> M </td>
   <td style="text-align:right;"> 78 </td>
   <td style="text-align:right;"> 56 </td>
   <td style="text-align:right;"> 33 </td>
   <td style="text-align:right;"> 724.83 </td>
   <td style="text-align:right;"> 742737.4 </td>
   <td style="text-align:left;"> NH1 </td>
   <td style="text-align:right;"> 148 </td>
   <td style="text-align:left;"> went </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 249 </td>
   <td style="text-align:right;"> 198 </td>
   <td style="text-align:right;"> 29 </td>
   <td style="text-align:left;"> word </td>
   <td style="text-align:right;"> 411.51 </td>
   <td style="text-align:right;"> 4.322 </td>
   <td style="text-align:right;"> 79.6 </td>
   <td style="text-align:right;"> 3.825 </td>
   <td style="text-align:right;"> 1.2 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:left;"> A15 </td>
   <td style="text-align:left;"> LTA </td>
   <td style="text-align:right;"> 21 </td>
   <td style="text-align:right;"> 16 </td>
   <td style="text-align:left;"> F </td>
   <td style="text-align:right;"> 95 </td>
   <td style="text-align:right;"> 57 </td>
   <td style="text-align:right;"> 9 </td>
   <td style="text-align:right;"> 483.71 </td>
   <td style="text-align:right;"> 861801.0 </td>
   <td style="text-align:left;"> A15 </td>
   <td style="text-align:right;"> 278 </td>
   <td style="text-align:left;"> went </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 249 </td>
   <td style="text-align:right;"> 198 </td>
   <td style="text-align:right;"> 29 </td>
   <td style="text-align:left;"> word </td>
   <td style="text-align:right;"> 411.51 </td>
   <td style="text-align:right;"> 4.322 </td>
   <td style="text-align:right;"> 79.6 </td>
   <td style="text-align:right;"> 3.825 </td>
   <td style="text-align:right;"> 1.2 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 1 </td>
   <td style="text-align:left;"> B18 </td>
   <td style="text-align:left;"> TLA </td>
   <td style="text-align:right;"> 69 </td>
   <td style="text-align:right;"> 11 </td>
   <td style="text-align:left;"> M </td>
   <td style="text-align:right;"> 85 </td>
   <td style="text-align:right;"> 54 </td>
   <td style="text-align:right;"> 10 </td>
   <td style="text-align:right;"> 517.62 </td>
   <td style="text-align:right;"> 1024583.4 </td>
   <td style="text-align:left;"> b18 </td>
   <td style="text-align:right;"> 318 </td>
   <td style="text-align:left;"> went </td>
   <td style="text-align:right;"> 4 </td>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 249 </td>
   <td style="text-align:right;"> 198 </td>
   <td style="text-align:right;"> 29 </td>
   <td style="text-align:left;"> word </td>
   <td style="text-align:right;"> 411.51 </td>
   <td style="text-align:right;"> 4.322 </td>
   <td style="text-align:right;"> 79.6 </td>
   <td style="text-align:right;"> 3.825 </td>
   <td style="text-align:right;"> 1.2 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>You can examine all the variables using <code>summary()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  item_number      subjectID             Test                Age       
 Min.   :  1.00   Length:5440        Length:5440        Min.   :16.00  
 1st Qu.: 40.75   Class :character   Class :character   1st Qu.:21.00  
 Median : 80.50   Mode  :character   Mode  :character   Median :21.00  
 Mean   : 80.50                                         Mean   :36.94  
 3rd Qu.:120.25                                         3rd Qu.:53.00  
 Max.   :160.00                                         Max.   :73.00  
 Years_in_education    Gender          TOWRE_wordacc    TOWRE_nonwordacc
 Min.   :11.00      Length:5440        Min.   : 68.00   Min.   :16.00   
 1st Qu.:13.00      Class :character   1st Qu.: 84.00   1st Qu.:50.00   
 Median :16.00      Mode  :character   Median : 93.00   Median :55.50   
 Mean   :14.94                         Mean   : 91.24   Mean   :52.41   
 3rd Qu.:16.00                         3rd Qu.: 98.00   3rd Qu.:57.00   
 Max.   :19.00                         Max.   :104.00   Max.   :63.00   
 ART_HRminusFR         RT               COT            Subject         
 Min.   : 1.00   Min.   :-2000.0   Min.   :  50094   Length:5440       
 1st Qu.: 7.00   1st Qu.:  498.1   1st Qu.: 297205   Class :character  
 Median :11.00   Median :  577.6   Median : 552854   Mode  :character  
 Mean   :15.15   Mean   :  565.3   Mean   : 575780                     
 3rd Qu.:21.00   3rd Qu.:  677.4   3rd Qu.: 810108                     
 Max.   :43.00   Max.   : 1978.4   Max.   :1583651                     
  Trial.order     item_name             Length       Ortho_N      
 Min.   : 21.0   Length:5440        Min.   :3.0   Min.   : 0.000  
 1st Qu.:100.8   Class :character   1st Qu.:4.0   1st Qu.: 3.000  
 Median :180.5   Mode  :character   Median :4.0   Median : 6.000  
 Mean   :180.5                      Mean   :4.3   Mean   : 7.069  
 3rd Qu.:260.2                      3rd Qu.:5.0   3rd Qu.:11.000  
 Max.   :340.0                      Max.   :6.0   Max.   :24.000  
     BG_Sum          BG_Mean       BG_Freq_By_Pos   item_type        
 Min.   :  3.00   Min.   :  1.00   Min.   :  1.0   Length:5440       
 1st Qu.: 81.75   1st Qu.: 67.75   1st Qu.: 74.5   Class :character  
 Median :151.50   Median :153.50   Median :158.0   Mode  :character  
 Mean   :155.89   Mean   :153.82   Mean   :149.6                     
 3rd Qu.:234.75   3rd Qu.:239.25   3rd Qu.:227.0                     
 Max.   :314.00   Max.   :316.00   Max.   :295.0                     
    SUBTLWF          LgSUBTLWF        SUBTLCD        LgSUBTLCD    
 Min.   :   0.57   Min.   :1.477   Min.   : 0.32   Min.   :1.447  
 1st Qu.:  17.36   1st Qu.:2.947   1st Qu.: 6.67   1st Qu.:2.748  
 Median :  69.30   Median :3.549   Median :23.64   Median :3.298  
 Mean   : 442.01   Mean   :3.521   Mean   :36.52   Mean   :3.137  
 3rd Qu.: 290.70   3rd Qu.:4.171   3rd Qu.:65.24   3rd Qu.:3.739  
 Max.   :6161.41   Max.   :5.497   Max.   :99.70   Max.   :3.922  
      OLD       
 Min.   :1.000  
 1st Qu.:1.288  
 Median :1.550  
 Mean   :1.512  
 3rd Qu.:1.750  
 Max.   :2.050  </code></pre>
</div>
</div>
<p>The summary shows some features of the dataset, or of how R interprets the dataset, that are of immediate interest to us, though we do not necessarily have to do anything about them.</p>
<ol type="1">
<li>We can see statistical summaries – showing the mean, median, minimum and maximum, etc. – of numeric variables like the outcome variable <code>RT</code>.</li>
<li>We can see statistical summaries, also, of variables that comprise number values but which we do not want to be treated as numbers, e.g., the word stimulus coding variable <code>item_number</code>.</li>
<li>We can see that some variables are simply listed as <code>Class: character</code>. That tells us that one or more values in the columns in the datasheet that correspond to these variables are words or strings of letters or alphanumeric characters.</li>
<li>There is no sign of the presence of missing values in this dataset, no counts of <code>NAs</code>.</li>
</ol>
<p>We do not really want R to treat a coding variable like <code>item_number</code> as numeric: it functions as a categorical or nominal variable, a factor. And we want R to treat coding variables like <code>subjectID</code> as factors. In <a href="01-multilevel.html#sec-multi-data-coerce"><span>Section&nbsp;3.8.3</span></a>, we saw how we can require R to handle variables exactly as we require it to using <em>coercion</em>. In <a href="02-mixed.html#sec-intro-mixed-data-load"><span>Section&nbsp;4.9.1</span></a>, we saw how we can determine how R treats variables at the read-in stage, using <code>col_types()</code> specification. We are going to do neither here because we do not have to do this work; not doing it will have no impact on our analyses at this point.</p>
<p>What we <strong>do need to do</strong> is deal with a problem that is already apparent in the summary statistics – did you spot it? If we look at the summary, we can see that <code>RT</code> includes values as low as <code>-2000</code>. That cannot be right.</p>
</section>
<section id="sec-dev-mixed-EDA" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="sec-dev-mixed-EDA"><span class="header-section-number">5.6.2</span> Examine the distribution of raw RT data using density plots</h3>
<p>We should examine the distribution of the outcome variable, lexical decision response reaction time (RT in ms). Observations about variable value distributions are a part of <em>Exploratory Data Analysis</em> and serve to catch errors in the dataset (e.g.&nbsp;incorrectly recorded scores) but also to inform the researcher’s understanding of their own data.</p>
<p>We shall examine the distribution of the outcome variable, lexical decision response reaction time (RT in ms), using density plots. An alternative method would be to use histograms. I choose to use density plots because they allow the easy comparison of the distributions of values of a continuous numeric variable like reaction time. A density plot shows a curve. You can say that the density corresponds to the height of the curve for a given value of the variable being depicted, and that it is related to the probability of observing values of the variable within some range of values <span class="citation" data-cites="howell2016fundamental">(<a href="references.html#ref-howell2016fundamental" role="doc-biblioref">Howell, 2016</a>)</span>.</p>
<p>Getting a density plot of RTs of responses is easy using <code>ggplot()</code> code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>ML.all <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> RT)) <span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rug</span>(<span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Raw RT"</span>) <span class="sc">+</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-rt-all-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-rt-all-density-1.png" class="img-fluid figure-img" alt="Density plot showing word recognition reaction time, correct and incorrect responses. The figure shows a black line, a curve peaking over RT = about 500 but ranging between -2000 and +2000. Under the curve, a series of black tick marks are shown under the x-axis border." width="480"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.1: Density plot showing word recognition reaction time, correct and incorrect responses</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The code delivers a plot (<a href="#fig-rt-all-density">Figure&nbsp;<span>5.1</span></a>) showing three peaks in the distribution of RT values. You can see that there is a peak of RT observations around 500-1000ms, another smaller peak around -500ms, and a third smaller peak around -2000ms.</p>
<p>The density plot shows the reaction times recorded for participants’ button press ‘yes’ responses to word stimuli in the lexical decision task. The peaks of negative RTs represent observations that are <em>impossible</em>.</p>
<p>Remember that reaction time, in a task like lexical decision, represents the interval in time between the onset of a task stimulus (in lexical decision, a word or a nonword) and the onset of the response (the button press to indicate the lexical decision). We cannot have negative time intervals. The explanation is that ML collected her data using the DMDX experimental software application <span class="citation" data-cites="Forster2003a">(<a href="references.html#ref-Forster2003a" role="doc-biblioref">Forster &amp; Forster, 2003</a>)</span>. DMDX records the reaction times for incorrect responses as <em>negative RTs</em>.</p>
<p>The code to produce <a href="#fig-rt-all-density">Figure&nbsp;<span>5.1</span></a> works in a series of steps.</p>
<ol type="1">
<li><code>ML.all %&gt;%</code> takes the dataset, from the ML study, that we have read in to the R workspace and pipes it to the visualization code, next.</li>
<li><code>ggplot(aes(x = RT)) +</code> creates a plot object in which the x-axis variable is specified as <code>RT</code>. The values of this variable will be mapped to geometric objects, i.e.&nbsp;plot features, that you can see, next.</li>
<li><code>geom_density(size=1.5) +</code> first displays the distribution of values in the variable <code>RT</code> as a density curve. The argument <code>size=1.5</code> tells R to make the line <span class="math inline">\(1.5 \times\)</span> the thickness of the line used by default to show variation in density.</li>
</ol>
<p>Some further information is added to the plot, next.</p>
<ol start="4" type="1">
<li><code>geom_rug(alpha = .2) +</code> with a command that tells R to add a rug plot below the density curve.</li>
<li><code>ggtitle("Raw RT")</code> makes a plot title.</li>
</ol>
<p>Notice that beneath the curve of the density plot, you can see a series of vertical lines. Each line represents the x-axis location of an RT observation in the ML study data set. This <em>rug plot</em> represents the distribution of RT observations in one dimension.</p>
<ul>
<li><code>geom_rug()</code> draws a vertical line at each location on the x-axis that we observe a value of the variable, RT, named in <code>aes(x = RT)</code>.</li>
<li><code>geom_rug(alpha = .2)</code> reduces the opacity of each line, using <code>alpha</code>, to ensure the reader can see how the RT observations are denser in some places than others.</li>
</ul>
<p>You can see that we have many more observations of RTs from around 250ms to 1250ms, where the rug of lines is thickest, under the peak of the density plot. This indicates what the two kinds of plots are doing.</p>
<section id="sec-dev-mixed-exx-viz" class="level4" data-number="5.6.2.1">
<h4 data-number="5.6.2.1" class="anchored" data-anchor-id="sec-dev-mixed-exx-viz"><span class="header-section-number">5.6.2.1</span> Exercise</h4>
<p>You should try out alternative visualisation methods to reveal the patterns in the distribution of variables in the ML dataset (or in your own data).</p>
<ol type="1">
<li>Take a look at the <code>geoms</code> documented in the <code>{ggplot2}</code> library reference section <a href="https://ggplot2.tidyverse.org/reference/#section-layer-geoms">here</a>.</li>
<li>Experiment with code to answer the following questions:</li>
</ol>
<ul>
<li>Would a histogram or a frequency polygon provide a more informative view? Take a look <a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">here for advice</a>.</li>
<li>What about a dotplot? Take a look <a href="https://ggplot2.tidyverse.org/reference/geom_dotplot.html">here for advice</a></li>
</ul>
</section>
</section>
<section id="sec-dev-mixed-data-filter" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="sec-dev-mixed-data-filter"><span class="header-section-number">5.6.3</span> Filter observations</h3>
<p>The density plot shows us that the raw ML lexical decision <code>RT</code> variable includes negative RT values corresponding to incorrect response. These have to be removed. We can do this quite efficiently by creating a subset of the original “raw” data, defined according to the RT variable using the <code>{dpyr}</code> library <code>filter()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="ot">&lt;-</span> <span class="fu">filter</span>(ML.all, RT <span class="sc">&gt;=</span> <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After we have removed negative (error) RTs, we check that the size of the dataset – here, the number of rows – matches our expectations. We do this to make sure that we did the filter operation correctly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(ML.all<span class="sc">$</span>RT)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5440</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(ML.all.correct<span class="sc">$</span>RT)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5257</code></pre>
</div>
</div>
<p>If you run the <code>length()</code> function calls then you should see that the <em>length</em> or number of observations or rows in the <code>ML.all.correct</code> dataset should be smaller than the number of observations in the <code>ML.all</code> dataset.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is wise to <em>check</em> that the operations you perform to tidy, process or wrangle data <em>actually do</em> do what you mean them to do. Checks can be performed, for each processing stage, by:</p>
<ol type="1">
<li>Forming expectations or predictions about what the operation is supposed to do e.g.&nbsp;filter out some rows by some number;</li>
<li>Check what you get against these predictions e.g.&nbsp;count the number of rows before versus after filtering.</li>
</ol>
</div>
</div>
<p>Having obtained a new data frame with data on just those trials where responses were correct, we can plot the distribution of RTs for just the correct responses (<a href="#fig-rt-correct-density">Figure&nbsp;<span>5.2</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="sc">%&gt;%</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> RT)) <span class="sc">+</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">size=</span><span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rug</span>(<span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Correct RTs"</span>) <span class="sc">+</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-rt-correct-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-rt-correct-density-1.png" class="img-fluid figure-img" alt="Density plot showing word recognition reaction time, correct and incorrect responses. The figure shows a black line, a curve peaking over RT = about 500 now ranging between 0 and +2000. Under the curve, a series of black tick marks are shown under the x-axis border. The skew towards high values is now more obvious." width="480"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.2: Density plot showing word recognition reaction time, correct responses only</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The filter code is written to subset the data by rows <strong>using a condition</strong> on the values of the RT variable.</p>
<p><code>ML.all.correct &lt;- filter(ML.all, RT &gt;= 200)</code> works as follows.</p>
<ol type="1">
<li><code>ML.all.correct &lt;- filter(ML.all ...)</code> creates a new dataset with a new name <code>ML.all.correct</code> from the old dataset <code>ML.all</code> using the <code>filter()</code> function.</li>
<li><code>filter(... RT &gt;= 200)</code> specifies an argument for the <code>filter()</code> function.</li>
</ol>
<p>In effect, we are asking R to check every value in the <code>RT</code> column.</p>
<ul>
<li>R will do a check through the <code>ML.all</code> dataset, row by row.</li>
<li><em>If</em> a row includes an RT that is greater than or equal to 200 <em>then</em> that row will be included in the new dataset <code>ML.all.correct</code>. This is what I mean by <strong>using a condition</strong>.</li>
<li><em>But if</em> a row includes an RT that is less than 200, then that row will not be included. We express this condition as <code>RT &gt;= 200</code>.</li>
</ul>
<p>The <code>length()</code> function will count the elements in whatever object is specified as an argument in the function call.</p>
<ul>
<li>This means that if you put a variable name into the function as in <code>length(dataset$variable)</code> it will count how long that variable is – how many rows there are in the column.</li>
<li>If that variable happens to be, as here, part of a dataset, the same calculation will tell you how many rows there are in the dataset as a whole.</li>
<li>If you just enter <code>length(dataset)</code>, naming some dataset, then the function will return a count of the number of columns in the dataset.</li>
</ul>
<section id="sec-dev-mixed-exx-filter" class="level4" data-number="5.6.3.1">
<h4 data-number="5.6.3.1" class="anchored" data-anchor-id="sec-dev-mixed-exx-filter"><span class="header-section-number">5.6.3.1</span> Exercise</h4>
<p>Vary the filter conditions in different ways.</p>
<ol type="1">
<li>Change the threshold for including RTs from <code>RT &gt;= 200</code> to something else: you can change the number, or you can change the operator from <code>&gt;=</code> to a different comparison (try <code>=, &lt;, &lt;=, &gt;</code>.</li>
<li>Can you assess what impact the change has?</li>
</ol>
<p>Note that you can count the number of observations (rows) in a dataset using e.g.&nbsp;<code>length()</code>.</p>
</section>
<section id="sec-dev-mixed-workflow-filter" class="level4" data-number="5.6.3.2">
<h4 data-number="5.6.3.2" class="anchored" data-anchor-id="sec-dev-mixed-workflow-filter"><span class="header-section-number">5.6.3.2</span> Filtering observations as a decision in the psychological research workflow</h4>
<p>I choose to filter out or exclude not only error responses (where <span class="math inline">\(RT &lt; 0ms\)</span>) but also short reaction times (where <span class="math inline">\(RT &lt; 200ms\)</span>). I think that any response in the lexical decision task that is recorded as less than 200ms cannot possibly represent a real word recognition response. Participants who complete experimental psychological tasks can and do press the button before they have time to engage the psychological processes (like word recognition) that the tasks we administer are designed to probe (like lexical decision).</p>
<p>There is some relevant literature that concerns the speed at which neural word recognition processes operate. However, I think you should note that the threshold I am setting for exclusion, here, is essentially <em>arbitrary</em>. If you think about it, I could have set the threshold at any number from <span class="math inline">\(100-300ms\)</span> or some other range.</p>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>What is guiding me in setting the filter threshold is experience. But other researchers will have different experiences and set different thresholds.</p>
<ul>
<li><em>This</em> is why using exclusion criteria to remove data is problematic.</li>
</ul>
</div>
</div>
<p>Filtering or re-coding observations is an important element of the research workflow in psychological science. How we do or do not remove observations from original data may have an impact on our results (as explored by <span class="citation" data-cites="steegen2016">Steegen et al. (<a href="references.html#ref-steegen2016" role="doc-biblioref">2016</a>)</span>). It is important, therefore, that we learn how to do this reproducibly using, for example, R scripts that we can share with our research reports.</p>
<p>I would argue that, at minimum, a researcher should report their research including:</p>
<ul>
<li>What exclusion criteria they use to remove data, explaining why.</li>
<li>Report analyses with and without exclusions, to indicate if their results are sensitive to their decisions.</li>
</ul>
<p>You can read further information about the practicalities of using R to do filtering <a href="https://r4ds.had.co.nz/transform.html?q=filter#filter-rows-with-filter">here</a>.</p>
<p>You can read a brief discussion of the impacts of researcher choices in dataset construction in <a href="intro.html#sec-multiversedata"><span>Section&nbsp;7.2.4.2</span></a> and in <span class="citation" data-cites="steegen2016">Steegen et al. (<a href="references.html#ref-steegen2016" role="doc-biblioref">2016</a>)</span>.</p>
</section>
</section>
<section id="sec-dev-mixed-data-transform" class="level3" data-number="5.6.4">
<h3 data-number="5.6.4" class="anchored" data-anchor-id="sec-dev-mixed-data-transform"><span class="header-section-number">5.6.4</span> Select or transform the variables: the log10 transformation of RT</h3>
<p><a href="#fig-rt-correct-density">Figure&nbsp;<span>5.2</span></a> shows that we have successfully removed all errors (negative RTs) but now we see just how skewed the RT distribution is. Note the <em>long tail</em> of longer RTs.</p>
<p>Most researchers assume that participants – healthy young adults – take about 500-1000ms to perform the task and that values outside that range correspond to either fast guesses (RTs that are too short) or to distracted or tired or bored responses (RTs that are too long). In theory, the lexical decision task should be probing automatic cognitive processes, measuring the steps from perception to visual word recognition in the time interval between the moment the stimulus is first shown and the moment the button is pressed by the participant to indicate a response. Thus, it might seem natural to exclude extreme RT values which might correspond not to automatic cognitive processes but to unknowable distraction events or boredom and inattention. However, we shall complete no further data exclusions.</p>
<p>For now, we can look at a commonly used method to deal with the skew that we typically see when we examine reaction time distributions. RT distributions are usually skewed with a long tail of longer RTs. You can always take longer to press the button but there is a limit to how much faster you can make your response.</p>
<p>Generally, we assume that departures from a model’s predictions about our observations (the linear model residuals) are normally distributed, and we often assume that the relationship between outcome and predictor variables is linear <span class="citation" data-cites="Cohen2003c">(<a href="references.html#ref-Cohen2003c" role="doc-biblioref">Cohen et al., 2003</a>)</span>. We can ensure that our data are compliant with both assumptions by transforming the RT distribution.</p>
<p>It is not <em>cheating</em> to transform variables. Transformations of data variables can be helpful for a variety of reasons in the analysis of psychological data <span class="citation" data-cites="Cohen2003c Gelman2007ga">(<a href="references.html#ref-Cohen2003c" role="doc-biblioref">Cohen et al., 2003</a>; <a href="references.html#ref-Gelman2007ga" role="doc-biblioref">Gelman &amp; Hill, 2007</a>)</span>. I do recommend, however, that you are careful to report what transformations you use, and why you do them.</p>
<p>Psychology researchers often take the log (often the log base 10) of RT values before performing an analysis. Transforming RTs to the log base 10 of RT values has the effect of correcting the skew – bringing the larger RTs ‘closer’ (e.g., <span class="math inline">\(1000 = 3\)</span> in log10) to those near the middle which do not change as much (e.g.&nbsp;<span class="math inline">\(500 = 2.7\)</span> in log10).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct<span class="sc">$</span>logrt <span class="ot">&lt;-</span> <span class="fu">log10</span>(ML.all.correct<span class="sc">$</span>RT)            </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see the effect of the transformation if we plot the log10 transformed RTs (see <a href="#fig-rt-correct-log-density">Figure&nbsp;<span>5.3</span></a>). We arrive at a distribution that more closely approximates the normal distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="sc">%&gt;%</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> logrt)) <span class="sc">+</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rug</span>(<span class="at">alpha =</span> .<span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Correct log10 RTs"</span>) <span class="sc">+</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-rt-correct-log-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-rt-correct-log-density-1.png" class="img-fluid figure-img" alt="Density plot showing word recognition reaction time, correct and incorrect responses. The figure shows a black line, a curve peaking over logrt = about 2.8 ranging between 2.4 and 3.5. Under the curve, a series of black tick marks are shown under the x-axis border. The skew towards high values is now considerably reduced." width="480"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.3: Density plot showing log10 transformed reaction time, correct responses only</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The <code>log10()</code> function works as follows:-</p>
<ol type="1">
<li><code>ML.all.correct$logrt &lt;- log10(...)</code> creates a a new variable <code>logrt</code>, adding it to the <code>ML.all.correct</code> dataset. The variable is created using the transformation function <code>log10()</code>.</li>
<li><code>log10(ML.all.correct$RT)</code> creates a the new variable by transforming (to log10) the values of the old variable, <code>RT</code>.</li>
</ol>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are other log transformation functions and we often see researchers using the natural log instead of the log base 10 as discussed <a href="https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/log">here</a></p>
</div>
</div>
</section>
<section id="sec-dev-mixed-data-tidy-conclusions" class="level3" data-number="5.6.5">
<h3 data-number="5.6.5" class="anchored" data-anchor-id="sec-dev-mixed-data-tidy-conclusions"><span class="header-section-number">5.6.5</span> Data tidying – conclusions</h3>
<p>Even when data have been structured appropriately, we will still, often, need to do some tidying before we can do an analysis. Most research work involving quantitative evidence requires a <em>big</em> chunk of data tidying or other processing before you get to the statistics.</p>
<p><strong>Our data are now ready for analysis.</strong></p>
</section>
</section>
<section id="sec-dev-mixed-crossed-random" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="sec-dev-mixed-crossed-random"><span class="header-section-number">5.7</span> Repeated measures designs and crossed random effects</h2>
<p>As we saw in <a href="02-mixed.html"><span>Chapter&nbsp;4</span></a>, many Psychologists conduct studies where it is not sensible to think of observations as being nested <span class="citation" data-cites="baayen2008">(<a href="references.html#ref-baayen2008" role="doc-biblioref">Baayen et al., 2008a</a>)</span>. In this chapter, we turn to the ML word recognition study dataset, which has a structure similar to the CP study data that we worked with previously. Again, the core concern is that the data come from a study with a <strong>repeated-measures design</strong> where the experimenter presented multiple stimuli for response to each participant, for several participants, so that we have multiple observations for each participant and multiple observations for each stimulus. Getting practice with this kind of data will help you to easily recognize what you have got when you see it in your own work.</p>
<p>ML asked all participants in a sample of people to read a selection of words, a sample of words from the language.</p>
<p>For each participant, we will have multiple observations and these observations will not be independent. One participant will tend to be slower or less accurate compared to another. Her responses may be more or less susceptible to the effects of the experimental variables. The lowest trial-level observations can be grouped with respect to participants. However, the data can also be grouped by stimuli.</p>
<p>For each stimulus word, there are multiple observations and these observations will not be independent. One stimulus may prove to be more challenging to all participants compared to another, eliciting slower or less accurate responses on average. In addition, if there are within-items effects, we may ask if the impact of those within-items effects is more prominent, stronger, among responses to some items compared to others.</p>
<p>Given this common <em>repeated-measures</em> design, we can analyse the outcome variable in relation to:</p>
<ul>
<li><strong>fixed effects</strong>: the impact of independent variables like participant reading skill or word frequency;</li>
<li><strong>random effects</strong>: the impact of random or unexplained differences between participants and also between stimuli.</li>
</ul>
</section>
<section id="sec-dev-mixed-working-lme" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="sec-dev-mixed-working-lme"><span class="header-section-number">5.8</span> Working with mixed-effects models</h2>
<p>We are going to respond to the multilevel (or crossed random effects) structure in the data by using linear mixed-effects models to analyze the data. This week, we are going to look at what mixed-effects models do from a <strong>new perspective</strong>.</p>
<p>Our concern will be with different ways of thinking about why mixed-effects models are superior to linear models where data have a multilevel structure. Mixed-effects models tend to be more accurate in this (very common) situation because of what is called <em>partial pooling</em> and <em>shrinkage</em> or <em>regularization</em>. We use our practical example to explore these ideas.</p>
<section id="sec-dev-mixed-viz-facetting" class="level3" data-number="5.8.1">
<h3 data-number="5.8.1" class="anchored" data-anchor-id="sec-dev-mixed-viz-facetting"><span class="header-section-number">5.8.1</span> Use facetting in ggplot to examine data by person</h3>
<p>To get started, we can examine – for each individual separately – the distribution of log RT observations, in <a href="#fig-rt-correct-log-den-by-subj">Figure&nbsp;<span>5.4</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="sc">%&gt;%</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(subjectID) <span class="sc">%&gt;%</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mean_logrt =</span> <span class="fu">mean</span>(logrt, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">subjectID =</span> <span class="fu">fct_reorder</span>(subjectID, mean_logrt)) <span class="sc">%&gt;%</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> logrt)) <span class="sc">+</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">size =</span> <span class="fl">1.25</span>) <span class="sc">+</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> subjectID) <span class="sc">+</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">2.778807</span>, <span class="at">colour =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">2.5</span>,<span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Plot showing distribution of logRT for each participant; red line shows mean log10 RT"</span>) <span class="sc">+</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-rt-correct-log-den-by-subj" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-rt-correct-log-den-by-subj-1.png" class="img-fluid figure-img" alt="The figure presents a grid of density plots showing log10 transformed reaction time, correct responses, separately for each participant. A dashed red line is drawn through all plots, indicating the mean RT. The curves vary in both the location of the peak and in the shape of the curve." width="768"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.4: Density plot showing log10 transformed reaction time, correct responses, separately for each participant</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-rt-correct-log-den-by-subj">Figure&nbsp;<span>5.4</span></a> shows that RT distributions vary considerably between people. The plot imposes a dashed red line to indicate where the mean log10 RT is, calculated over all observations in the dataset. The plot shows the distribution of log RT for each participant, as a density drawn separately for each person. The individual plots are ordered by the mean log RT calculated per person, so plots appear in order from the fastest to the slowest.</p>
<p>The grid of plots illustrates some interesting features about the data in the ML study sample. You can see how the distribution of log RT varies between individuals: some people show widely spread reaction times; some people show quite tight or narrow distributions. You can see how the shapes of the distributions varies: some people show skew; others do not. I do not see that the variation in the shapes of the distributions is related to the average speed of the person’s responses.</p>
<p>I think the key message of the plot is that some distributions are wider (RTs are more spread out) than others. We might be concerned that people who present more variable reaction times (wider distributions) may be associated with less reliable estimates of their average response speed, or of the impact of word attributes (like word frequency) on their response speed.</p>
<section id="combining-data-processing-and-plotting-code-sec-dev-mixed-combine-wrangling-plotting" class="level4" data-number="5.8.1.1">
<h4 data-number="5.8.1.1" class="anchored" data-anchor-id="combining-data-processing-and-plotting-code-sec-dev-mixed-combine-wrangling-plotting"><span class="header-section-number">5.8.1.1</span> Combining data processing and plotting code {sec-dev-mixed-combine-wrangling-plotting}</h4>
<p>The plotting code I used to produce <a href="#fig-rt-correct-log-den-by-subj">Figure&nbsp;<span>5.4</span></a> progresses through a series of steps. This example demonstrates how you can combine data tidying and plotting steps in a single sequence, using <code>tidyverse</code> functions and the <code>%&gt;%</code> pipe, so I will take the time to explain what is going on.</p>
<p>My aim is to create a grid of individual plots, showing the distribution of log RTs for each participant, so that the plots are presented in order, from the fastest participant to the slowest. Take a look at the plotting code. We can explain how it works, step by step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="sc">%&gt;%</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(subjectID) <span class="sc">%&gt;%</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mean_logrt =</span> <span class="fu">mean</span>(logrt, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">subjectID =</span> <span class="fu">fct_reorder</span>(subjectID, mean_logrt)) <span class="sc">%&gt;%</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> logrt)) <span class="sc">+</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">size =</span> <span class="fl">1.25</span>) <span class="sc">+</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> subjectID) <span class="sc">+</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">2.778807</span>, <span class="at">colour =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">2.5</span>,<span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Plot showing distribution of logRT for each participant; red line shows mean log10 RT"</span>) <span class="sc">+</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You will see that we present the distribution of RTs using <code>geom_density()</code> and that we present a separate plot for each person’s data using <code>facet_wrap()</code>. To these elements, we add some pre-processing steps to calculate the average response speed of each individual, and to reorder the dataset by those averages.</p>
<p>It will make it easier to understand what is going on if we consider the code in chunks.</p>
<p>First, we pre-process the data before we feed it into the plotting code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(subjectID) <span class="sc">%&gt;%</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mean_logrt =</span> <span class="fu">mean</span>(logrt, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">subjectID =</span> <span class="fu">fct_reorder</span>(subjectID, mean_logrt)) <span class="sc">%&gt;%</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li><code>ML.all.correct %&gt;%</code> takes the selected filtered dataset <code>ML.all.correct</code> and pipes it <code>%&gt;%</code> to the next step.</li>
<li><code>group_by(subjectID) %&gt;%</code> tells R to group the data by <code>subject ID</code>. We have a set of multiple log RT observations for each <code>subjectID</code> because each participant was asked to respond to multiple word stimuli.</li>
<li><code>mutate(mean_logrt = mean(logrt, na.rm = TRUE))</code> next calculates and stores the mean log RT for each person. We create a new variable <code>mean_logrt</code>. We calculate the average of the set of log RTs recorded for each <code>subjectID</code> and construct the new variable <code>mean_logrt</code> from these averages.</li>
</ol>
<p>We do not need to treat the data in groups so we remove the grouping, next.</p>
<ol start="4" type="1">
<li>Using <code>ungroup() %&gt;%</code> means that, having grouped the data to calculate the mean log RTs, we <code>ungroup</code> the dataset so that R can look at all observations in the next step.</li>
<li><code>mutate(subjectID = fct_reorder(subjectID, mean_logrt)) %&gt;%</code> asks R to look at all log RT observations in the dataset, and change the top-to-bottom order of the rows.</li>
</ol>
<p>We ask R to order observations – using <code>subjectID</code> in <code>fct_reorder()</code> – so that each person’s data are listed by their average speed, <code>mean_logrt</code> from the fastest to the slowest. We then pipe these ordered data to the plotting code, next.</p>
<p>If you delete or comment out these first lines, you will see that R uses just a default ordering, drawing the plot for each person in the alphabetical order of their <code>subjectID</code> codes.</p>
<p>Try it. Don’t forget to start with <code>ML.all.correct %&gt;%</code>.</p>
<p>Second, we draw the plots, using the data we have pre-processed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct <span class="sc">%&gt;%</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> logrt)) <span class="sc">+</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">size =</span> <span class="fl">1.25</span>) <span class="sc">+</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> subjectID) <span class="sc">+</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The key functions that create a grid of density plots are the following.</p>
<ol type="1">
<li><code>ggplot(aes(x = logrt))</code> tells R to work with <code>logrt</code> as the x-axis variable. We shall be plotting the distribution of <code>logrt</code>.</li>
<li><code>geom_density(...)</code> draws a density plot to show the distribution of log RT, using a thicker line <code>size = 1.25</code></li>
<li><code>facet_wrap(~ subjectID)</code> creates a different plot for each level of the <code>subjectID</code> factor: we want to see a separate plot for each participant.</li>
</ol>
<ul>
<li><code>facet_wrap(~ subjectID)</code> works to split the dataset up by participant, with observations corresponding to each participant identified by their <code>subjectID</code>, and to then split the plotting to show the distribution of log RT separately for each participant.</li>
</ul>
<p>I wanted to present the plots in order of the average speed of response of participants. If you look at <a href="#fig-rt-correct-log-den-by-subj">Figure&nbsp;<span>5.4</span></a>, you can see that the position of the peak of the log RT distribution for each participant moves, from the fastest plots where the peak is around <span class="math inline">\(log RT = 2.5\)</span> (shown from the top left of the grid), to the slowest plots where the peak is around <span class="math inline">\(log RT = 2.75\)</span> (shown towards the bottom right of the grid)</p>
<p>We can then use further <code>ggplot</code> functions to edit the appearance of the plot, to make it more useful.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">2.778807</span>, <span class="at">colour =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="fl">2.5</span>,<span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Plot showing distribution of logRT for each participant; red line shows mean log10 RT"</span>) <span class="sc">+</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol type="1">
<li><code>geom_vline(xintercept = 2.778807, colour = "red", linetype = 2)</code> draws a vertical red dashed line at the location of the mean log RT, the average of all log RTs over all participants in the dataset.</li>
<li><code>scale_x_continuous(breaks = c(2.5,3))</code> adjusts the x-axis labeling. The <code>ggplot</code> default might draw too many x-axis labels i.e.&nbsp;showing possible log RT values as tick marks on the bottom line of the plot. I want to avoid this as sometimes all the labels can be crowded together, making them harder to read.</li>
</ol>
<ul>
<li>Drawing a vertical line at the mean calculated overall is designed to help the reader (you) calibrate their comparison of the data from different people.</li>
</ul>
</section>
<section id="sec-dev-mixed-exx-viz-histograms" class="level4" data-number="5.8.1.2">
<h4 data-number="5.8.1.2" class="anchored" data-anchor-id="sec-dev-mixed-exx-viz-histograms"><span class="header-section-number">5.8.1.2</span> Exercises</h4>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is often useful to experiment with example code to figure out how it works.</p>
</div>
</div>
<p>One way you can do this is by commenting out one line of code, at a time by putting the <code>#</code> at the start of the line.</p>
<ul>
<li>If you do this, you can see what the line of code does by, effectively, asking R to ignore it.</li>
</ul>
<p>Another way you can experiment with code is by seeing what you can change and what effect the changes have.</p>
<ol type="1">
<li>Can you work out how to adapt the plotting code to show a grid of histograms instead of density plots?</li>
<li>Can you work out how to adapt the code to show a grid of plots indicating the distribution of log RT by different words instead of participants?</li>
</ol>
</section>
</section>
<section id="sec-dev-mixed-complete-pooling" class="level3" data-number="5.8.2">
<h3 data-number="5.8.2" class="anchored" data-anchor-id="sec-dev-mixed-complete-pooling"><span class="header-section-number">5.8.2</span> Approximations to Linear Mixed-effects models: complete pooling</h3>
<p>As we have discussed in previous chapters, a good way to approach a mixed-effects analysis is by first estimating the effects of the experimental variables (here, frequency) using linear models, <em>ignoring</em> the hierarchical structure in the data.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>A linear model of multilevel structured data can be regarded as an <strong>approximation</strong> to the better analysis.</p>
</div>
</div>
<p>We model the effects of interest, using all the data (hence, <em>complete pooling</em>) but ignoring the differences between participants. This means we can see something of the ‘true’ picture of our data through the linear model results but the linear model misses important information, which the mixed-effects model will include, that would improve its performance.</p>
<p>As we saw, in a similar analysis in <span class="quarto-unresolved-ref">?sec-sec-intro-mixed</span>, we can estimate the relationship between reading reaction times (here, lexical decision RTs) and word frequency using a linear model:</p>
<p><span class="math display">\[
Y_{ij} = \beta_0 + \beta_1X_j + e_{ij}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(Y_{ij}\)</span> is the value of the observed outcome variable, the log RT of the response made by the <span class="math inline">\(i\)</span> participant to the <span class="math inline">\(j\)</span> item;</li>
<li><span class="math inline">\(\beta_1X_j\)</span> refers to the fixed effect of the explanatory variable (here, word frequency), where the frequency value <span class="math inline">\(X_j\)</span> is different for different words <span class="math inline">\(j\)</span>, and <span class="math inline">\(\beta_1\)</span> is the estimated coefficient of the effect due to the relationship between response speed and word frequency;</li>
<li><span class="math inline">\(e_{ij}\)</span> is the residual error term, representing the differences between observed <span class="math inline">\(Y_{ij}\)</span> and predicted values (given the model) for each response made by the <span class="math inline">\(i\)</span> participant to the <span class="math inline">\(j\)</span> item.</li>
</ul>
<p>The linear model is fit in R using the <code>lm()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lm  <span class="ot">&lt;-</span> <span class="fu">lm</span>(logrt <span class="sc">~</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                             </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                             LgSUBTLCD,     </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                           </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">data =</span> ML.all.correct)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = logrt ~ LgSUBTLCD, data = ML.all.correct)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.41677 -0.07083 -0.01163  0.05489  0.53411 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.885383   0.007117  405.41   &lt;2e-16 ***
LgSUBTLCD   -0.033850   0.002209  -15.32   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1095 on 5255 degrees of freedom
Multiple R-squared:  0.04277,   Adjusted R-squared:  0.04259 
F-statistic: 234.8 on 1 and 5255 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>In the estimates from this linear model, we see an approximate first answer to our prediction.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Research hypothesis: Words that are shorter, that look like more other words, and that appear frequently in the language will be easier to recognize.</li>
<li>Result: We can see that, in this first analysis, the estimated effect of word frequency is <span class="math inline">\(\beta = -0.033850\)</span>.</li>
</ul>
</div>
</div>
<p>I know this looks like a very small number but you should realize that the estimates for the coefficients of fixed effects like the frequency effect are scaled according to the outcome. Here, the outcome is log10 RT, where a log10 RT of 3 equals 1000ms, and, as we can calculate in R</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log10</span>(<span class="fl">0.925</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -0.03385827</code></pre>
</div>
</div>
<p>Also, remember that frequency is scaled in logs too, so the estimate of the coefficient tells us how log10 RT changes for unit change in log frequency. The coefficient represents the estimated change in log10 RT for unit change in log frequency <code>LgSUBTLCD</code>.</p>
<p>The estimate indicates that as word log frequency increases, responses logRT <em>decreases</em> by <span class="math inline">\(-0.033850\)</span>.</p>
<p>In this model, all the information from all participants is analyzed. In discussions of mixed-effects analyses, we say that this is a <em>complete pooling</em> model. This is because <em>all the data have been pooled together</em>, that is, we use all observations in the sample to estimate the effect of frequency.</p>
<p>In this model, the observations are assumed to be independent. However, we suppose that the assumption of independence is questionable given the expectation that participants will differ in their overall speed, and in the extent to which their response speed is affected by factors like word frequency.</p>
<section id="exercises" class="level4" data-number="5.8.2.1">
<h4 data-number="5.8.2.1" class="anchored" data-anchor-id="exercises"><span class="header-section-number">5.8.2.1</span> Exercises</h4>
<ol type="1">
<li>Vary the linear model using different outcomes or predictors.</li>
</ol>
<ul>
<li>The ML study data, like the CP study data, are rich with possibility. It would be useful to experiment with it.</li>
</ul>
<ol start="2" type="1">
<li>Change the predictor from frequency to something else: what do you see when you visualize the relationship between outcome and predictor variables using scatterplots?</li>
<li>Specify linear models with different predictors: do the relationships you see in plots match the coefficients you see in the model estimates?</li>
</ol>
<p>I would recommend that you both estimate the effects of variables <em>and</em> visualize the relationships between variables using scatterplots. If you combine reflection on the model estimates with evaluation of what the plots show you then you will be able to see how reading model results and reading plots can reveal the correspondences between the two ways of looking at your data.</p>
</section>
</section>
<section id="sec-dev-mixed-no-pooling" class="level3" data-number="5.8.3">
<h3 data-number="5.8.3" class="anchored" data-anchor-id="sec-dev-mixed-no-pooling"><span class="header-section-number">5.8.3</span> Approximations to Linear Mixed-effects models: no pooling</h3>
<p>We can examine variation between participants by analyzing the data for each participant’s responses separately, fitting a <em>different</em> linear model of the effect of word frequency on lexical decision RTs for each participant <em>separately</em>. <a href="#fig-no-vs-complete">Figure&nbsp;<span>5.5</span></a> presents a grid or trellis of plots, one plot per person. In each plot, you can see points corresponding to the log RT of the responses made by each participant to the stimulus words.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>In working with R, we often benefit from the vast R knowledge ecosystem.</p>
<ul>
<li>I was able to produce the sequence of plots <a href="#fig-no-vs-complete">Figure&nbsp;<span>5.5</span></a>, <a href="#fig-no-vs-complete-vs-partial">Figure&nbsp;<span>5.6</span></a>, <a href="#fig-no-vs-complete-vs-partial-zoom">Figure&nbsp;<span>5.7</span></a> and <a href="#fig-shrinkage">Figure&nbsp;<span>5.8</span></a> thanks to <a href="https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/">this very helpful blog post by TJ Mahr</a></li>
</ul>
</div>
</div>
<p>In all plots, the pink or red line represents the <em>complete pooling</em> model estimate of the effect of frequency on response RTs. The line is the same for each participant because there is only one estimated effect, based on all data for all participants.</p>
<p>In addition, in each plot, you can see a green line. You can see that the line varies between participants. This represents the effect of frequency estimated using just the data for each participant, analyzed separately. These are the <em>no pooling</em> estimates. We call them the no pooling estimates because each is based just on the data from one participant.</p>
<div class="cell" data-hash="03-mixed_cache/html/fig-no-vs-complete_2c5d61c6bf6a9a106c05adc05d7e9f4d">
<div class="cell-output-display">
<div id="fig-no-vs-complete" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-no-vs-complete-1.png" class="img-fluid figure-img" alt="The figure shows a grid of plots. Each plot shows the relationship between logRT and log frequency (LgSUBTLCD) separately for each participant. A red-pink line shows the complete pooling estimate. Different blue-green lines shows the no-pooling estimate given the data for each participant." width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.5: Plot showing the relationship between logRT and log frequency (LgSUBTLCD) separately for each participant; red-pink line shows the complete pooling estimate, blue-green line shows the no-pooling estimate</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-no-vs-complete">Figure&nbsp;<span>5.5</span></a> reveals substantial differences between participants in both average response speed and the frequency effect.</p>
<p>We may further predict variation in standard errors between participants given, also, the differences between participants in the spread of log RT, illustrated by <a href="#fig-rt-correct-log-den-by-subj">Figure&nbsp;<span>5.4</span></a>. Basically, where the distribution of log RT is more widely spread out, for any one participant, there it will be harder for us to estimate with certainty the mean or the sources of variance for the participant’s response speed.</p>
<p>You will notice that the <em>no pooling</em> and <em>complete pooling</em> estimates tend to be quite similar. But for some participants – more than for others – there is variation between the estimates.</p>
<p>You can reflect that the <em>complete pooling</em> is unsatisfactory because it ignores the variation between the participants: some people <em>are</em> slower than others; some people <em>do</em> show a larger frequency effect than others. You can also reflect that the <em>no pooling</em> is unsatisfactory because it ignores the similarities between the participants.</p>
<p>While there <em>is</em> variation between participants there is also similarity across the group so that the effect of frequency is similar between participants.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>What we need is an analytic method that is capable of <em>both</em> estimating the overall average population-level effect (here, of word frequency) <em>and</em> taking into account the differences between sampling units (here, participants).</p>
<p><strong>That method is linear mixed-effects modeling.</strong></p>
</div>
</div>
</section>
</section>
<section id="sec-dev-mixed-lme" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="sec-dev-mixed-lme"><span class="header-section-number">5.9</span> The linear mixed-effects model</h2>
<section id="sec-dev-mixed-fixed-random" class="level3" data-number="5.9.1">
<h3 data-number="5.9.1" class="anchored" data-anchor-id="sec-dev-mixed-fixed-random"><span class="header-section-number">5.9.1</span> Fixed and random effects</h3>
<p>As you have seen before, we can account for the variation – the differences between participants in intercepts and slopes.</p>
<p>First, we model the intercept as two terms:</p>
<p><span class="math display">\[
\beta_{0i} = \gamma_0 + U_{0i}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\gamma_{0}\)</span> is the average intercept, and</li>
<li><span class="math inline">\(u_{0i}\)</span> is the difference for each participant between their intercept and the average intercept.</li>
</ul>
<p>Second, we can model the frequency effect as two terms:</p>
<p><span class="math display">\[
\beta_{1i} = \gamma_1 + U_{1i}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\gamma_{10}\)</span> is the average slope, and:</li>
<li><span class="math inline">\(U_{1i}\)</span> represents the difference for each participant between the slope of their frequency effect and the average slope.</li>
</ul>
<p>We can then incorporate in a single model the <strong>fixed effects</strong> due to the average intercept and the average frequency effect, as well as the <strong>random effects</strong> – the error variance due to unexplained differences between participants in intercepts and in frequency effects:</p>
<p><span class="math display">\[
Y_{ij} = \gamma_0 + \gamma_1X_j + U_{0i}+ U_{1i}X_j + e_{ij}
\]</span></p>
<p>Where the outcome <span class="math inline">\(Y_{ij}\)</span> is related to:</p>
<ul>
<li>the average intercept <span class="math inline">\(\gamma_0\)</span> and differences between <span class="math inline">\(i\)</span> participants in the intercept <span class="math inline">\(U_{0i}\)</span>;</li>
<li>the average effect of the explanatory variable frequency <span class="math inline">\(\gamma_1X_j\)</span> and differences between <span class="math inline">\(i\)</span> participants in the slope <span class="math inline">\(U_{1i}X_j\)</span>;</li>
<li>in addition to residual error variance <span class="math inline">\(e_{ij}\)</span>.</li>
</ul>
</section>
<section id="sec-dev-mixed-variance-covariance" class="level3" data-number="5.9.2">
<h3 data-number="5.9.2" class="anchored" data-anchor-id="sec-dev-mixed-variance-covariance"><span class="header-section-number">5.9.2</span> Variance and covariance</h3>
<p>As we first saw in <a href="02-mixed.html"><span>Chapter&nbsp;4</span></a>, in conducting mixed-effects analyses, we do not aim to examine the specific deviation (here, for each participant) from the average intercept or the average effect or slope. We estimate just the spread of deviations by-participants.</p>
<p>A mixed-effects model like our final model actually includes fixed effects corresponding to the intercept and the slope of the word frequency effect plus the variances:</p>
<ul>
<li><span class="math inline">\(var(U_{0i})\)</span> variance of deviations by-participants from the average intercept;</li>
<li><span class="math inline">\(var(U_{1i}X_j)\)</span> variance of deviations by-participants from the average slope of the frequency effect;</li>
<li><span class="math inline">\(var(e_{ij})\)</span> residuals, at the response level, after taking into account all other terms.</li>
</ul>
<p>We may expect the random effects of participants or items to <em>covary</em>: for example, participants who are slow to respond may also be more susceptible to the frequency effect. Thus our specification of the random effects of the model can incorporate terms corresponding to the covariance of random effects:</p>
<ul>
<li><span class="math inline">\(covar(U_{0i}, U_{1i}X_j)\)</span></li>
</ul>
</section>
<section id="sec-dev-mixed-random-stimulus-effects" class="level3" data-number="5.9.3">
<h3 data-number="5.9.3" class="anchored" data-anchor-id="sec-dev-mixed-random-stimulus-effects"><span class="header-section-number">5.9.3</span> Random effects of differences between stimuli</h3>
<p>As we know, some words elicit slower and some elicit faster responses on average. As we discussed in the last chapter (<a href="02-mixed.html#sec-intro-mixed-fixed-effect-fallacy"><span>Section&nbsp;4.10</span></a>), if we did not take such variation into account, we might spuriously identify an experimental effect actually due just to unexplained between-items differences in intercepts <span class="citation" data-cites="clark1973 raaijmakers1999">(<a href="references.html#ref-clark1973" role="doc-biblioref">Clark, 1973</a>; <a href="references.html#ref-raaijmakers1999" role="doc-biblioref">Raaijmakers et al., 1999</a>)</span> committing an error: <em>the language as fixed effect fallacy</em>.</p>
<p>We can model the random effect of items on intercepts by modeling the intercept as two terms:</p>
<p><span class="math display">\[
\beta_{0j} = \gamma_0 + W_{0j}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\gamma_{0}\)</span> is the average intercept, and</li>
<li><span class="math inline">\(W_{0j}\)</span> represents the deviation, for each word, between the average intercept and the per-word intercept.</li>
</ul>
<p>Note that I ignore the possibility, for now, of differences between items in the slopes of fixed effects but I <em>do</em> come back to this.</p>
<p>The term <em>the language as fixed effect fallacy</em> <span class="citation" data-cites="clark1973 raaijmakers1999">(<a href="references.html#ref-clark1973" role="doc-biblioref">Clark, 1973</a>; <a href="references.html#ref-raaijmakers1999" role="doc-biblioref">Raaijmakers et al., 1999</a>)</span> implies that thinking about the random effects of stimulus differences applies only when we are looking at experiments about language. But you should remember that we need to think about the impact of random differences between stimuli whenever we present samples of stimuli to participants, and we collect observations about multiple responses for each stimulus. This is true whatever the nature of the stimuli <span class="citation" data-cites="judd2012">(see e.g. <a href="references.html#ref-judd2012" role="doc-biblioref">Judd et al., 2012</a>)</span>.</p>
</section>
<section id="sec-dev-mixed-random-participants-stimuli" class="level3" data-number="5.9.4">
<h3 data-number="5.9.4" class="anchored" data-anchor-id="sec-dev-mixed-random-participants-stimuli"><span class="header-section-number">5.9.4</span> A model including random effects of differences between stimuli as well as participants</h3>
<p>Our model can <em>now</em> incorporate the random effects of participants as well as items:</p>
<p><span class="math display">\[
Y_{ij} = \gamma_0 + \gamma_1X_j + U_{0i}+ U_{1i}X_j + W_{0j} + e_{ij}
\]</span></p>
<p>In this model, the outcome <span class="math inline">\(Y_{ij}\)</span> is related to:</p>
<ul>
<li>the average intercept <span class="math inline">\(\gamma_0\)</span> and the word frequency effect <span class="math inline">\(\gamma_1X_j\)</span>;</li>
<li>plus random effects due to unexplained differences between participants in intercepts <span class="math inline">\(U_{0i}\)</span> and in the slope of the frequency effect <span class="math inline">\(U_{1i}X_j\)</span>;</li>
<li>as well as random differences between items in intercepts <span class="math inline">\(W_{0j}\)</span>;</li>
<li>in addition to the residual term <span class="math inline">\(e_{ij}\)</span>.</li>
</ul>
</section>
<section id="sec-dev-mixed-lmer" class="level3" data-number="5.9.5">
<h3 data-number="5.9.5" class="anchored" data-anchor-id="sec-dev-mixed-lmer"><span class="header-section-number">5.9.5</span> Fitting a mixed-effect model using lmer()</h3>
<p>We fit a mixed-effects model of the <span class="math inline">\(logrt \sim \text{frequency}\)</span> relationship using the <code>lmer()</code> function, taking into account:</p>
<ul>
<li>the fact that the study data have a hierarchical structure – with observations sensibly grouped by participant;</li>
<li>the fact that both the frequency effect, and average speed, may vary between participants;</li>
<li>and the fact that the average speed of response can vary between responses to different stimuli.</li>
</ul>
<p>The model syntax corresponds to the statistical formula and the code is written as:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                           LgSUBTLCD <span class="sc">+</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                           (LgSUBTLCD <span class="sc">+</span> <span class="dv">1</span><span class="sc">|</span>subjectID) <span class="sc">+</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>                           (<span class="dv">1</span><span class="sc">|</span>item_name),</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> ML.all.correct)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As will now be getting familiar, the code works as follows:</p>
<ol type="1">
<li><code>ML.all.correct.lmer  &lt;- lmer(...)</code> creates a <em>linear mixed-effects model</em> object using the <code>lmer()</code> function.</li>
<li><code>logrt ~ LgSUBTLCD</code> the fixed effect in the model is expressed as a formula in which the outcome or dependent variable <code>logrt</code> is predicted <code>~</code> by the independent or predictor variable <code>LgSUBTLCD</code> word frequency.</li>
</ol>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>If there were more terms in the model, the terms would be added in series separated by <code>+</code></p>
</div>
</div>
<p>The random effects part of the model is then specified as follows.</p>
<ol start="3" type="1">
<li>We first have the random effects associated with random differences between participants:</li>
</ol>
<ul>
<li><code>(...|subjectID)</code> adds random effects corresponding to random differences between sample groups (participants subjects) coded by the <code>subjectID</code> variable.</li>
<li><code>(...1 |subjectID)</code> including random differences between sample groups (<code>subjectID</code>) in intercepts coded <code>1</code>.</li>
<li><code>(LgSUBTLCD... |subjectID)</code> and random differences between sample groups (<code>subjectID</code>) in the slopes of the frequency effect coded by using the<code>LgSUBTLCD</code> variable name.</li>
</ul>
<ol start="4" type="1">
<li>Then, we have the random effects associated with random differences between stimuli:</li>
</ol>
<ul>
<li><code>(1|item_name)</code> adds a random effect to account for random differences between sample groups (<code>item_name</code>) in intercepts coded <code>1</code>.</li>
</ul>
<ol start="5" type="1">
<li><code>...(..., data = ML.all.correct)</code> specifies the dataset in which you can find the variables named in the model fitting code.</li>
<li>Lastly, we can then specify <code>summary(ML.all.correct.lmer)</code> to get a summary of the fitted model.</li>
</ol>
</section>
<section id="sec-dev-mixed-lmer-results" class="level3" data-number="5.9.6">
<h3 data-number="5.9.6" class="anchored" data-anchor-id="sec-dev-mixed-lmer-results"><span class="header-section-number">5.9.6</span> Reading the lmer() results</h3>
<p>If you run the model code as written then you would see the following results.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>                           LgSUBTLCD <span class="sc">+</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                           (LgSUBTLCD <span class="sc">+</span> <span class="dv">1</span><span class="sc">|</span>subjectID) <span class="sc">+</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>                           (<span class="dv">1</span><span class="sc">|</span>item_name),</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> ML.all.correct)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lmer)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: logrt ~ LgSUBTLCD + (LgSUBTLCD + 1 | subjectID) + (1 | item_name)
   Data: ML.all.correct

REML criterion at convergence: -9868.1

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.6307 -0.6324 -0.1483  0.4340  5.6132 

Random effects:
 Groups    Name        Variance  Std.Dev. Corr 
 item_name (Intercept) 0.0003268 0.01808       
 subjectID (Intercept) 0.0054212 0.07363       
           LgSUBTLCD   0.0002005 0.01416  -0.63
 Residual              0.0084333 0.09183       
Number of obs: 5257, groups:  item_name, 160; subjectID, 34

Fixed effects:
             Estimate Std. Error t value
(Intercept)  2.887997   0.015479 186.577
LgSUBTLCD   -0.034471   0.003693  -9.333

Correlation of Fixed Effects:
          (Intr)
LgSUBTLCD -0.764</code></pre>
</div>
</div>
<p>In these results, we see:</p>
<ol type="1">
<li>First, information about the function used to fit the model, and the model object created by the <code>lmer()</code> function call.</li>
<li>Then, we see the model formula <code>logrt ~ LgSUBTLCD + (LgSUBTLCD + 1|subjectID) + (1|item_name)</code>.</li>
<li>Then, we see <code>REML criterion at convergence</code> about the model fitting process, which we can usually ignore.</li>
<li>Then, we see information about the distribution of the model residuals.</li>
<li>Then, we see the<code>Random Effects</code>.</li>
</ol>
<p>Notice that the statistics are <code>Variance Std.Dev. Corr.</code>, that is, the variance, the corresponding standard deviation, and the correlation estimates associated with the random effects.</p>
<ul>
<li>We see <code>Residual</code> error variance, just like in a linear model, corresponding to a distribution or spread of deviations between the model prediction and the observed RT for each response made by a participant to a stimulus.</li>
<li>We see <code>Variance</code> terms corresponding to what can be understood as group-level residuals. Here, the variance due to random differences between the average intercept (over all data) and the intercept for each participant, and the variance due to random differences between the average slope of the frequency effect and the slope for each participant.</li>
<li>We also see the variance due to random differences between the average intercept (over all data) and the intercept for responses to each word stimulus.</li>
<li><em>And</em> we see the <code>Corr</code> estimate, telling us about the <em>covariance</em> between random deviations (between participants) in the intercepts and in the slopes of the frequency effect.</li>
</ul>
<ol start="6" type="1">
<li>Last, just as for linear models, we see estimates of the coefficients (of the slopes) of the fixed effects, the intercept and the slope of the <code>logrts ~ LgSUBTLCD</code> relationship.</li>
</ol>
<p>We can compare this estimate with our previous <code>lm()</code> estimate for the effect of frequency.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Research hypothesis: Words that are shorter, that look like more other words, and that appear frequently in the language will be easier to recognize.</li>
<li>Result: We can see that, in this mixed-effects analysis, the estimated effect of word frequency is now <span class="math inline">\(\beta = -0.034471\)</span>.</li>
</ul>
</div>
</div>
<p>The estimate is different, a bit smaller. While the change in the estimate is also small, we may remember that we are looking at slope estimates for predicted change in <em>log RT</em>, in an experimental research area in which effects are often of the order of 10s of milliseconds. The estimates, and changes in the estimates, will tend to be quite small.</p>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that we see coefficient estimates, as in a linear model summary but no p-values.</p>
<ul>
<li>We will come back to this, see <a href="#sec-dev-mixed-discussion-p-values"><span>Section&nbsp;5.13.4</span></a>.</li>
<li>However, note that if <span class="math inline">\(t &gt;= 2\)</span> we can suppose that (for a large dataset) an effect is significant at the <span class="math inline">\(.05\)</span> significance level.</li>
</ul>
</div>
</div>
</section>
</section>
<section id="sec-dev-mixed-regularisation" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="sec-dev-mixed-regularisation"><span class="header-section-number">5.10</span> Mixed-effects models, partial pooling, and shrinkage or regularisation of estimates</h2>
<p>What is the impact of the incorporation of random effects – the variance and covariance terms – in mixed-effects models? Mixed-effects models can be understood, in general, as a method to compromise between ignoring the differences between groups (here, participants constitute groups of data) as in <em>complete pooling</em> or focusing entirely on each group (participant) as in <em>no pooling</em> <span class="citation" data-cites="Gelman2007ga">(<a href="references.html#ref-Gelman2007ga" role="doc-biblioref">Gelman &amp; Hill, 2007</a>)</span>. In this discussion, I am going to refer to the differences between participants but you can assume that the lesson applies generally to any situation in which you have different units in a multilevel structured dataset in which the units correspond to groups or clusters of data.</p>
<section id="sec-dev-mixed-overfitting" class="level3" data-number="5.10.1">
<h3 data-number="5.10.1" class="anchored" data-anchor-id="sec-dev-mixed-overfitting"><span class="header-section-number">5.10.1</span> Overfitting</h3>
<p>The problem with ignoring the differences between groups (participants), as in the <em>complete pooling</em> model (here, the linear model), has been obvious when we examined the differences between participants (or between classes) in slopes and intercepts in previous weeks. The problem with focusing entirely on each participant, as in the <em>no pooling</em> model, has not been made apparent in our discussion yet.</p>
<p>If we analyze each participant separately then we will get, for each participant, for our model of the frequency effect, the per-participant estimate of the intercept and the per-participant estimate of the slope of the frequency effect. These no-pooling estimates will tend to exaggerate or overstate the differences between participants <span class="citation" data-cites="Gelman2007ga">(<a href="references.html#ref-Gelman2007ga" role="doc-biblioref">Gelman &amp; Hill, 2007</a>)</span>. By basing the estimates on just the data for a person, in each per-participant analysis, the no-pooling approach <em>overfits</em> the data.</p>
<p>You could say that the no-pooling approach gives us estimates that depend <em>too much</em> on the sample of data we have got, and are unlikely to be similar to the estimates we would see in other samples in future studies.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>The no-pooling estimates are too strongly influenced by the data we are currently analyzing.</p>
</div>
</div>
</section>
<section id="sec-dev-mixed-partial-pooling" class="level3" data-number="5.10.2">
<h3 data-number="5.10.2" class="anchored" data-anchor-id="sec-dev-mixed-partial-pooling"><span class="header-section-number">5.10.2</span> Partial pooling: shrinkage or borrowing strength</h3>
<p>If we look closely at <a href="#fig-no-vs-complete">Figure&nbsp;<span>5.5</span></a>, we can see that there are similarities as well as differences between participants. Our analysis must take both into account.</p>
<p>What happens in mixed-effects models is that we pool information, calculating the estimates for each participant, in part based on the information we have for the whole sample (all participants, in complete pooling), in part based on the information we have about the specific participant (one participant, in no pooling). Thus, for example, the estimated intercept for a participant in a mixed-effects model is given by the weighted average <span class="citation" data-cites="Snijders2004a">(<a href="references.html#ref-Snijders2004a" role="doc-biblioref">Snijders &amp; Bosker, 2004</a>)</span> of:</p>
<ul>
<li>the intercept estimate given by an analysis of just that participant’s data (no pooling estimate;</li>
<li>and the intercept estimate given by analysis of all participants’ data (complete pooling estimate).</li>
</ul>
<p>The weighted average will reflect our relative level of information about the participant’s responses compared to how much information we have about all participants’ responses.</p>
<p>For some participants, we will have less information – maybe they made many errors, so we have fewer correct responses for an analysis. For these people, because we have less information, the intercept estimate will get pulled (shrunk) towards the overall (complete pooling, all data) estimate.</p>
<p>For other participants, we have more information – maybe they made all correct responses. For these people, because we have more information, the intercept estimate will be based more on the data for each participant.</p>
<p>To make sense of what this means, think about the differences between participants in how much reliable information we can have, given our sample, about their average level of response speed or about how they are affected by experimental variables. Think back to my comments about <a href="#fig-rt-correct-log-den-by-subj">Figure&nbsp;<span>5.4</span></a>, about the differences between participants in how spread out the distributions of their log RT values are. Recall that I said that where participants’ responses are more spread out – just as where we have less observations for some participants than for others – we shall inevitably have less certainty about our estimates for the effects that influence their performance if we base our account on just their data. Mixed-effects models perform better – as prediction models – than <em>no pooling</em> approaches because they are not relying, for any participant, on just their sometimes unreliable data.</p>
<p>We can look again at a plot showing the data for each participant. <a href="#fig-no-vs-complete-vs-partial">Figure&nbsp;<span>5.6</span></a> presents a grid or trellis of plots, one plot per person. In each plot, you can see points corresponding to the RT of each response made by a participant to a stimulus word. In all plots, the pink line represents the <em>complete pooling</em> data model estimate of the effect of frequency on response RTs. In each plot, the green line represents the effect of frequency estimated using just the data for each participant, the <em>no pooling</em> estimates. Now, we also see blue lines that represent the mixed-effects model <em>partial pooling</em> estimates.</p>
<div class="cell" data-hash="03-mixed_cache/html/fig-no-vs-complete-vs-partial_f8b07e44d11a09dc5883b1674817bb84">
<div class="cell-output-display">
<div id="fig-no-vs-complete-vs-partial" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-no-vs-complete-vs-partial-1.png" class="img-fluid figure-img" alt="The figure shows a grid of plots. Each plot shows the relationship between logRT and log frequency (LgSUBTLCD) separately for each participant. A red-pink line shows the complete pooling estimate. Different blue-green lines shows the no-pooling estimate given the data for each participant. The blue lines show the linear mixed-effects model partial pooling estimate for each participant." width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.6: Plot showing the relationship between logRT and log frequency (LgSUBTLCD) separately for each participant; pink line shows the complete pooling estimate green line shows the no-pooling estimate; and blue line shows the linear mixed-effects model partial pooling estimate</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>It is quite difficult to identify, in this sample, where the partial pooling and no pooling estimates differ. We can focus on a few clear examples. <a href="#fig-no-vs-complete-vs-partial-zoom">Figure&nbsp;<span>5.7</span></a>) presents a grid of plots for just four participants. I have picked some extreme examples but the plot illustrates how: (1.) for some participants e.g.&nbsp;<code>AA1</code> all estimates are practically identical; (2.) for some participants <code>EB5 JL3 JP3</code> the no-pooling and complete-pooling estimates are really quite different and (3.) for some participants <code>JL3 JP3</code> the no-pooling and partial-pooling estimates are quite different.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-no-vs-complete-vs-partial-zoom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-no-vs-complete-vs-partial-zoom-1.png" class="img-fluid figure-img" alt="The figure shows a grid of 4 plots, one plot each for participants AA1, EB5, JL3 and JP3. Each plot shows the relationship between logRT and log frequency (LgSUBTLCD) separately for each participant. A red-pink line shows the complete pooling estimate. Different blue-green lines shows the no-pooling estimate given the data for each participant. The blue lines show the linear mixed-effects model partial pooling estimate for each participant." width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.7: Plot showing the relationship between logRT and log frequency (LgSUBTLCD) separately for each participant – for participants AA1, EB5, JL3 and JP3; pink line shows the complete pooling estimate green line shows the no-pooling estimate; and blue line shows the linear mixed-effects model partial pooling estimate</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In general, partial pooling will apply both to estimates of intercepts and to estimates of the slopes of fixed effects like the influence of word frequency in reaction time. Likewise, if we consider this idea in general, we can see how it should work whether we are talking about groups or clusters of data grouped by participant or by stimulus or by school, class or clinic, etc.</p>
<p>Formally, whether an estimate for a participant (in our example) is pulled more or less towards the overall estimate will depend not just on the number of data-points we have for that person. The optimal combined estimate for a participant is termed the <em>Empirical Bayes estimate</em> and the weighting – the extent to which the per-participant ‘estimate’ depends on the participant’s data or the overall data – depends on the reliability of the estimate (of the intercept or the frequency effect) given by analyzing that participant’s data <span class="citation" data-cites="Snijders2004a">(<a href="references.html#ref-Snijders2004a" role="doc-biblioref">Snijders &amp; Bosker, 2004</a>)</span>. If you think about it, smaller samples – e.g.&nbsp;where a participant completed less correct responses – will give you less reliable estimates (and so will samples that show more variation).</p>
<p>What we are looking at, here, is a form of <em>regularization</em> in which we use all the sources of information we can to ensure we take into account the variability in the data while not getting over-excited by extreme differences <span class="citation" data-cites="mcelreath2020">(<a href="references.html#ref-mcelreath2020" role="doc-biblioref">McElreath, 2020</a>)</span>. We want to see estimates pulled towards an overall average where we have little data or unreliable estimates. We can see how strongly estimates can be shrunk in a plot like <a href="#fig-shrinkage">Figure&nbsp;<span>5.8</span></a>.</p>
<p><a href="#fig-shrinkage">Figure&nbsp;<span>5.8</span></a> illustrates the shrinkage effect. I plotted a scatterplot of intercept and slope parameters from each model (models with different kinds of pooling), and connect estimates for the same participant. The plot uses arrows to connect the different estimates for each participant, different estimates from no-pooling (per-participant) compared to partial-pooling (mixed-effects) models. The plot shows how more extreme estimates are shrunk towards the global average estimate.</p>
<div class="cell" data-hash="03-mixed_cache/html/fig-shrinkage_509134d145ce06a118dfaea5492dbfef">
<div class="cell-output-display">
<div id="fig-shrinkage" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-mixed_files/figure-html/fig-shrinkage-1.png" class="img-fluid figure-img" alt="The figure presents a scatterplot. The points represent point slope and intercept estimates. There are big green and pink points showing the complete pooling and partial pooling (average) estimates for the slope and intercept. There are also orange and purple points show the no pooling (orange) and partial pooling (purple) estimates for each person: estimates for a person are connected by arrows to show the direction towards which no pooling estimates are pulled or shrunk. The figure shows that shrinkage, indicated by longer arrows, is greater for some participants with more extreme estimates relative to the complete pooling or average estimates." width="624"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.8: Plot illustrating shrinkage: big green and pink points show the complete pooling and partial pooling (average) estimates for the slope and intercept; orange and purple points show the no pooling (orange) and partial pooling (purple) estimates for each person; estimates for a person are connected by arrows to show the direction towards which no pooling estimates are pulled or shrunk</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>We can see how estimates are pulled towards the average intercept and frequency effect estimates. The shrinkage effect is stronger for more extreme estimates like <code>JL3 JP3</code>. It is weaker for estimates more (realistically) like the overall group estimates like <code>AA1</code>.</p>
</section>
</section>
<section id="sec-dev-mixed-estimation" class="level2" data-number="5.11">
<h2 data-number="5.11" class="anchored" data-anchor-id="sec-dev-mixed-estimation"><span class="header-section-number">5.11</span> Estimation methods – An intuitive account of estimation in mixed-effects models</h2>
<p>Before we move on, we can think briefly about how the mixed-effects models are estimated <span class="citation" data-cites="Snijders2004a">(<a href="references.html#ref-Snijders2004a" role="doc-biblioref">Snijders &amp; Bosker, 2004</a>)</span>. Where do the numbers come from? I am happy to stick to a fairly non-technical intuitive explanation of the computation of LMEs but others, wishing to understand things more deeply, can find computational details in <span class="citation" data-cites="Pinheiro2000aa">Pinheiro &amp; Bates (<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">2000</a>)</span>, among other places. Mixed-effects models are estimated <em>iteratively</em>:</p>
<!-- %Snijders and boskers/p. 89             -->
<ul>
<li>If we knew the random effects, we could find the fixed effects estimates by minimizing differences – like linear modeling.</li>
<li>If we knew the fixed effects – the regression coefficients – we could work out the residuals and the random effects.</li>
</ul>
<p>At the start, we know neither, but we can move between partial estimation of fixed and random effect in an iterative approach.</p>
<ul>
<li>Using provisional values for the fixed effects to estimate the random effects.<br>
</li>
<li>Using provisional values for the random effects to estimate the fixed effects again.<br>
</li>
<li>To <em>converge</em> on the maximum likelihood estimates of effects – when the estimates stop changin.</li>
</ul>
<p>In mixed-effects models, the things that are estimated are the fixed effects (the intercept, the slope of the frequency effect, in our example), along with the variance and correlation terms associated with the random effects. Previously, I referred to the partial-pooling mixed-effects ‘estimates’ of the intercept or the frequency effect for each person, using the quotation marks because, strictly, these estimates are actually predictions, <em>Best Unbiased Linear Predictions (BLUPs)</em>, based on the estimates of the fixed and random effects.</p>
<section id="sec-dev-mixed-convergence-problems" class="level3" data-number="5.11.1">
<h3 data-number="5.11.1" class="anchored" data-anchor-id="sec-dev-mixed-convergence-problems"><span class="header-section-number">5.11.1</span> Convergence problems</h3>
<p>Mostly, our main concern, in working with mixed-effects models, is over what effects we should include, what model we should specify. But we should prepare for the fact sometimes happens that models <em>fail to converge</em>, which is to say, the model fitting algorithm fails to settle on some set of parameter estimates but has reached the limit in the number of iterations over which it has attempted to find a satisfactory set of estimates.</p>
<p>In my experience, convergence problems do arise, typically, if one is analyzing categorical outcome data (e.g accuracy) where there may be not enough observations to distinguish satisfactory estimates given a quite complex hypothesized model. In other words, you might run into convergence problems but it will not happen often and only where you are already dealing with quite a complex situation. We take a look at this concern in more depth, in the next chapter <a href="04-glmm.html"><span>Chapter&nbsp;6</span></a>.</p>
</section>
</section>
<section id="sec-dev-mixed-evaluating" class="level2" data-number="5.12">
<h2 data-number="5.12" class="anchored" data-anchor-id="sec-dev-mixed-evaluating"><span class="header-section-number">5.12</span> Fitting and evaluating Linear Mixed-effects models</h2>
<p>Up to this point, we have discussed the empirical or conceptual reasons we should expect to take into account, in our model, the effects on the outcome due to systematic differences in the experimental variables, e.g., in stimulus word frequency frequency, or to random differences between participants or between stimuli. We can now think about how we should statistically evaluate the relative usefulness of these different fixed effects or random effects, where usefulness is judged in relation to our capacity to explain outcome variance, or to improve model fit to sample data. We shall take an approach that follows the approach set out by Baayen, Bates and others <span class="citation" data-cites="Baayen2008 bates2015parsimonious matuschek2017">(<a href="references.html#ref-Baayen2008" role="doc-biblioref">Baayen et al., 2008b</a>; <a href="references.html#ref-bates2015parsimonious" role="doc-biblioref">Bates et al., 2015</a>; <a href="references.html#ref-matuschek2017" role="doc-biblioref">Matuschek et al., 2017</a>)</span>.</p>
<p>In this approach, we shall look at the choices that psychology researchers have to make. Researchers using statistical models are always faced with choices. As we have seen, these choices begin even before we start to do analyses, as when we make decisions about dataset construction <span class="citation" data-cites="steegen2016">(<a href="references.html#ref-steegen2016" role="doc-biblioref">Steegen et al., 2016</a>)</span>. The need to make choices is always present for all the kinds of models we work with (as I discuss in <a href="intro.html#sec-multiverse"><span>Section&nbsp;7.2.4</span></a>) though this may not always be obvious because, for example, in using some data analysis software, researchers may rely on defaults with limited indication that that is what they are doing.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Just because we are making choices does not mean we are operating subjectively in a non-scientific fashion. Rather, provided we work in an appropriate mode of transparency or reflexiveness, we can work with an awareness of our options and the context for the data analysis (see the very helpful discussion in <span class="citation" data-cites="gelman2017">Gelman &amp; Hennig (<a href="references.html#ref-gelman2017" role="doc-biblioref">2017</a>)</span>).</p>
</div>
</div>
<section id="sec-dev-mixed-model-comparison" class="level3" data-number="5.12.1">
<h3 data-number="5.12.1" class="anchored" data-anchor-id="sec-dev-mixed-model-comparison"><span class="header-section-number">5.12.1</span> Model comparison approach</h3>
<p>It is very common to see researchers using a process of model comparison to try to identify an account for their data in terms of estimates of fixed and random effects. A few key concepts are relevant to taking this approach effectively.</p>
<p>We will focus on building a series of models up to the <strong>most complex model supported by the data</strong>. What does <em>model complexity</em> mean here? I am talking about something like the difference between a model including just main effects (simpler) and a model including both main effects and the interaction between the effects (more complex), or, I am talking about a model included just fixed effects (simpler) versus a model including fixed effects as well as random effects (more complex).</p>
<p>Researchers may engage in comparing models to examine <strong>if one or more random effects should be included</strong> in their linear mixed-effects model. They may not be sure if they should include all random effects, that is, all random effects that could be included, given a range of grouping variables, like participant, class or stimulus, and given a range of possible effects, such as whether slopes or intercepts might vary.</p>
<p>Researchers may do model comparison to <strong>check if adding the effect of an experimental variable is justified</strong>. Maybe they are conducting an exploratory study in which they want to investigate if using some measurement variable helps to explain variation in the outcome. Perhaps they are conducting an experimental study in which they want to test if the experimental manipulation, or the difference between conditions, has an impact on the outcome.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Across these scenarios, we can test if an effect <em>should be included</em> or if its inclusion in a model <em>is justified</em> by comparing models with versus without the term that corresponds to the effect.</p>
</div>
</div>
<p>In some studies, researchers conduct model comparisons like this in order to obtain null hypothesis significance tests for the effects of the experimental variables.</p>
<p>Typically, the model comparisons are focused on whether some measurement of model fit is or is not different when we do versus do not include the effect in question in the model.</p>
<section id="sec-dev-mixed-exx-model-comparison" class="level4" data-number="5.12.1.1">
<h4 data-number="5.12.1.1" class="anchored" data-anchor-id="sec-dev-mixed-exx-model-comparison"><span class="header-section-number">5.12.1.1</span> Exercise – Model comparison questions</h4>
<p>As our discussion progresses, I think it would be helpful to reflect on some of the questions that you may be asking yourself.</p>
<p><strong>1. What about multiple comparisons?</strong></p>
<p>You might well ask yourself:</p>
<ul>
<li>If we engage in a bunch of comparisons to check if we should or should not include a variable, isn’t this just exploiting <em>researcher degrees of freedom</em>?</li>
</ul>
<p>Or, you might ask:</p>
<ul>
<li>If we are conducting multiple tests on the same data, aren’t we running the risk of raising the Type I error (false positive) rate because we are doing <em>multiple comparisons</em>?</li>
</ul>
<p>I think these are good questions but, here, my task is to explain what people do, why they do it, and how it helps in your data analysis.</p>
<p><strong>2. Is any model the best?</strong></p>
<ul>
<li>So you are looking at models with varying fixed effects (fitted using ML) or models with varying random effects (fitted using REML). How do you decide which model is better?</li>
</ul>
<p>Some researchers argue that trying to decide which model is better or best is inappropriate <span class="citation" data-cites="Gelman2015a">(see e.g. <a href="references.html#ref-Gelman2015a" role="doc-biblioref">a. Gelman, 2015</a>)</span>. As the famous saying by George Box has it <span class="citation" data-cites="box1976">(<a href="references.html#ref-box1976" role="doc-biblioref">Box, 1976</a>)</span>: “All models are wrong.” <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> We may say, nevertheless, that some models are useful. Some models are more useful than others, perhaps, because they explain or predict outcomes better, depending on your criteria, and the cost-benefit analysis.</p>
<p>Here, I will explain the model comparison process while acknowledging this point. This is because researchers often model comparison techniques to evaluate the relative usefulness of different alternate models.</p>
</section>
</section>
<section id="sec-dev-mixed-IC" class="level3" data-number="5.12.2">
<h3 data-number="5.12.2" class="anchored" data-anchor-id="sec-dev-mixed-IC"><span class="header-section-number">5.12.2</span> Model comparison using information criteria, AIC and BIC</h3>
<p>You will often encounter, in the psychological research literature, Information Criteria statistics like BIC: they are understood within an approach: <em>Information-theoretic methods</em>. They are grounded in the insight that you have reality and then you have approximating models. The distance between a model and reality corresponds to the information lost when we use a model to approximate reality. Information criteria – AIC or BIC – are estimates of <em>information loss</em>. The process of model selection aims to minimize information loss.</p>
<p>I will not discuss information criteria methods of model evaluation in detail, here, because psychologists frequently use the Likelihood Ratio Test method (<span class="citation" data-cites="meteyard2020a">Meteyard &amp; Davies (<a href="references.html#ref-meteyard2020a" role="doc-biblioref">2020</a>)</span>), see following. (Take a look at, e.g., <span class="citation" data-cites="Burnham2004">Burnham (<a href="references.html#ref-Burnham2004" role="doc-biblioref">2004</a>)</span> for a readable discussion, if you are interested.) However, you should have some idea of what information criteria statistics (like AIC and BIC) mean because you will see these statistics in the outputs from model comparisons using the <code>anova()</code> function, which we shall review a bit later (<a href="#sec-dev-mixed-LRT"><span>Section&nbsp;5.12.3</span></a>).</p>
<p>In summary, Akaike showed you could estimate information loss in terms of the likelihood of the model given the data – Akaike Information Criteria, <em>AIC</em>:</p>
<!-- % % burnham & anderson 2001/p.3 -->
<!-- % % baguleypp. 402 -- -->
<p><span class="math display">\[
AIC = -2ln(l) + 2k
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(-2ln(l)\)</span> is -2 times the log of the likelihood of the model given the data,</li>
<li>where <span class="math inline">\((l)\)</span> the likelihood</li>
<li>is proportional to the probability of observed data conditional on some hypothesis being true.</li>
</ul>
<p>You want a more likely model – less information loss, closer to reality – you want more negative or lower AIC. You can identify models that are more likely – closer to reality – with models with less wide errors, i.e.&nbsp;smaller residuals.</p>
<p>You could better approximate reality by including lots of predictors, specifying a more complex model. Models with more parameters may fit the data better but some of those effects may be spurious. Adding <span class="math inline">\(+ 2k\)</span> penalizes complexity, speaking crudely, and so helps us to focus on the more parsimonious less complex model that best fits the data.</p>
<p>Schwartz proposed an alternative estimate – Bayesian Information Criteria: <em>BIC</em>:</p>
<!-- % % burnham & anderson 2001/p.3 -->
<!-- % % baguleypp. 402 -- -->
<p><span class="math display">\[
BIC = -2ln(l) + kln(N)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(-2ln(l)\)</span> is -2 times the log of the likelihood of the model given the data.</li>
<li><span class="math inline">\(+ kln(N)\)</span> is the number of parameters in the model times the log of the sample size.</li>
</ul>
<p>Thus the penalty for greater complexity is heavier in BIC.</p>
<p>We see that AIC and BIC differ in the second term. A deeper difference is that AIC estimates information loss when the true model may not be among the models being considered while BIC assumes that the true model is within the set of models being considered.</p>
<p>At this point we just need to think about <em>Model selection and judgment</em> using AIC and BIC.</p>
<!-- % % burnham & anderson 2001/p.3 -->
<p>Compare a simpler model: model 1, just main effects; model 2, main effects plus interactions.</p>
<ul>
<li>If the more complex model better approximates reality then it will be more likely given the data.</li>
<li>BIC or AIC will be closer to negative infinity: <span class="math inline">\(-2ln(l)\)</span> will be larger e.g.&nbsp;10 is better than 1000, -1000 better than -10.</li>
</ul>
<p>AIC and BIC should move in the same direction. They usually will.</p>
<p>AIC will tend to allow more complex models and that may be necessary when the researcher is engaged in a more exploratory study or wants more accurate predictions (that would be better supported by maximising the information going into the model). Using the BIC will tend to favour simpler models and that may be necessary when the researcher seeks models that replicate over the long run. Maybe a simpler model will less likely include predictors estimated because they are needed to fit noise or random outcome variation.</p>
</section>
<section id="sec-dev-mixed-LRT" class="level3" data-number="5.12.3">
<h3 data-number="5.12.3" class="anchored" data-anchor-id="sec-dev-mixed-LRT"><span class="header-section-number">5.12.3</span> Model comparison using the Likelihood Ratio Test</h3>
<p><span class="citation" data-cites="Pinheiro2000aa Barr2013a matuschek2017">(<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">Pinheiro &amp; Bates, 2000</a>; see also <a href="references.html#ref-Barr2013a" role="doc-biblioref">Barr et al., 2013</a>; <a href="references.html#ref-matuschek2017" role="doc-biblioref">Matuschek et al., 2017</a>)</span> recommend that models of varying predictor sets can be compared using Likelihood Ratio Test comparison (LRTs) where the simple model is <em>nested</em> inside the more complex model. The “nested”, here, means that the predictors in the simpler model are a subset of the predictors in the more complex model. For example, you might have just main effects in the simpler model but both main and interaction effects in the more complex model. Or, in another example, you might have just random effects of subjects or items on intercepts in the simpler model but both random effects on intercepts and random effects on slopes of fixed effects in the more complex model.</p>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>When you compare models using the <em>Likelihood ratio test, LRT</em>, you are comparing alternate models of the <em>same data</em>.</p>
</div>
</div>
<p><span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span> note that we can compare models varying in the fixed effects (but constant in the random effects) or models varying in the random effects (but constant in the fixed effects) using LRTs. I have frequently reported model comparisons using the <em>Likelihood ratio test, LRT</em>. In part, this is for analytic reasons: I can compare simple and complex models getting multiple information criteria statistics for the models being compared in one function call, <code>anova([model1], [model2]</code>. In part, it is for social pragmatic reasons: the LRT comparison yields a significance p-value so that I can say, using the comparison, something like “The more complex model provided a significantly better fit to observation (LRT comparison, … p <span class="math inline">\(=\)</span> …”</p>
<p>In a <em>Likelihood ratio test, LRT</em>, the test statistic is the comparison of the likelihood of the simpler model with the more complex model. Fortunately for us, we can R to calculate the model likelihood and do the model comparison (<span class="quarto-unresolved-ref">?sec-dev-mixed-model-anova</span>).</p>
<p>The comparison of models works by division: we divide the likelihood of the more complex model by the likelihood of the simpler model, calculating a <em>likelihood ratio</em>.</p>
<p><span class="math display">\[
\chi^2 = 2log\frac{likelihood-complex}{likelihood-simple}
\]</span></p>
<p>The likelihood ratio is compared to the <span class="math inline">\(\chi^2\)</span> distribution for a significance test. In this significance test, we assume the null hypothesis that the simpler model is adequate as an account of the outcome variance. We calculate the p-value for the significance test using a number for the degrees of freedom equal to the difference in the number of parameters of the models being compared.</p>
</section>
</section>
<section id="sec-dev-mixed-model-steps" class="level2" data-number="5.13">
<h2 data-number="5.13" class="anchored" data-anchor-id="sec-dev-mixed-model-steps"><span class="header-section-number">5.13</span> Modeling steps recommendations</h2>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>How should you proceed when you decide to use mixed-effects models?</p>
<ul>
<li>I think the answer to that question depends on whether you are doing a study that is <strong>confirmatory</strong> or <strong>exploratory</strong>.</li>
</ul>
</div>
</div>
<p>In short, <em>if</em> you have <strong>pre-registered</strong> the design of your study and, as part of that registration, you recorded the hypotheses you plan to test, as well as the analysis method you plan to use to test your hypotheses, then the answer is simple: <strong>fit the model you said you were going to use</strong>.</p>
<p>But <em>if</em> you are doing an <strong>exploratory</strong> study, then you will need to make some choices, in part, depending on the nature of the sample you are working with, and other aspects of the research context, but it will help to <strong>keep things simple</strong>. These days, if you have not pre-registered your analysis plans, you are practically-speaking engaged in exploratory work.</p>
<p>In an exploratory study, I would keep things simple by comparing a series of models, fitted with different sets of predictor variables (fixed effects).</p>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note: if you are running mixed-effects models in R you cannot run <code>lmer()</code> models with just fixed effects.</p>
</div>
</div>
<p>What I do is this: for a dataset like the ML study data, where the data were collected using a repeated-measures design:</p>
<ul>
<li>so that all participants saw all stimuli,</li>
<li>and both participants and stimuli were sampled (from the wider populations of readers or words),</li>
<li>then I would run a series of models</li>
<li>so that the different models have <em>varying</em> sets of fixed effects</li>
<li>but all models in the series have the <em>same</em> random effects: the random effects of subjects and items on intercepts.</li>
</ul>
<p>In my experience, the estimates <em>and associated significance levels</em> associated with fixed effects can vary quite a bit depending on what other variables are included in the model. This has led me to take an approach where I am <em>not</em> varying too much how predictors are included in the model.</p>
<p>As noted, this will not really apply if you are doing an <em>confirmatory</em> study in which you are obliged to include the manipulated variables. However, if you are doing something a bit more <em>exploratory</em> then you might have to think about the kinds of predictors you include in your model, and how or when you include them.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>In what order should you examine the usefulness of different sets of fixed effects?</p>
<ul>
<li>This is a difficult question to answer and the difficulty is one reason why I think we need to be cautious when we engage in model comparison to try to get to a model of our data.</li>
</ul>
</div>
</div>
<p>My advice would be to plan out in advance a sequence of model comparisons.</p>
<ul>
<li>You should begin with simpler models with fewer effects.</li>
<li>You should begin with those effects whose impacts are well established and well understood by you.</li>
<li>If there is a whole set of well established effects typically included in an analysis in the field in which you are working, it might be sensible to include all the effects in a single step.</li>
<li>Then, I would use subsequent incremental steps to increase model complexity by adding effects that are theoretically justified, i.e., hypothesized, but which may be new, or may depend on the experimental manipulation you are testing out.</li>
</ul>
<p>Having established a model with some set of sensible fixed effects (guided by information criteria or LRT statistics), I would then turn my attention to the random effects component of the model. As noted, we may expect to see random differences between subjects (and possibly between items) in both the level of average performance – random effects of subjects or items on intercepts – and in the slopes of fixed effects – random effects of subjects or items on slopes.</p>
<p>What I do is this:</p>
<ul>
<li>For a dataset like ML’s, I examine firstly if both random effects of subjects <em>and</em> items on intercepts are required.</li>
<li>I then check if random effects of subjects or items on slopes are <em>additionally</em> required in the model.</li>
</ul>
<p>The distinction between <em>exploratory</em> and <em>confirmatory</em> studies breaks down, in my experience, when we start thinking about what random effects should be included in a model <span class="citation" data-cites="Barr2013a">Matuschek et al. (<a href="references.html#ref-matuschek2017" role="doc-biblioref">2017</a>)</span>.</p>
<section id="sec-dev-mixed-REML" class="level3" data-number="5.13.1">
<h3 data-number="5.13.1" class="anchored" data-anchor-id="sec-dev-mixed-REML"><span class="header-section-number">5.13.1</span> Maximum Likelihood and Restricted Maximum Likelihood</h3>
<p>Before we go any further, we need to briefly discuss one key choice that we face in working with mixed-effects models. This concerns the difference between Restricted Maximum Likelihood (REML) and Maximum Likelihood (ML) estimation methods. Both methods are iterative.</p>
<p>The <code>lmer()</code> function has defaults, like any analysis function, so we often do not need to make the choice explicit. We do need to when we compare models that vary in fixed effects, or in random effects.</p>
<ol type="1">
<li>Restricted maximum likelihood</li>
</ol>
<p>In R: <code>REML=TRUE</code> is stated in the <code>lmer()</code> function call.</p>
<ul>
<li>REML estimates the variance components while taking into account the loss of degrees of freedom resulting from the estimation of the fixed effects: <strong>REML estimates vary <em>if the fixed effects vary</em></strong>.</li>
<li>Therefore it is not recommended to compare the likelihood of models varying in fixed effects and fitted using REML <span class="citation" data-cites="Pinheiro2000aa">(<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">Pinheiro &amp; Bates, 2000</a>)</span>.</li>
<li>The REML method is recommended for comparing the likelihood of models with the same fixed effects but different random effects.</li>
<li>REML is more accurate for random effects estimation.</li>
</ul>
<ol start="2" type="1">
<li>Maximum likelihood</li>
</ol>
<p>In R: <code>REML=FALSE</code> is stated in the<code>lmer()</code> function call.</p>
<ul>
<li>ML estimation methods can be used to fit models with varying fixed effects but the same random effects.<br>
</li>
<li>ML estimation: a good place to start when building-up model complexity – adding parameters to an empty model.</li>
</ul>
<p><span class="citation" data-cites="Pinheiro2000aa">Pinheiro &amp; Bates (<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">2000</a>)</span> advise that the approach is anti-conservative (it will sometimes indicate effects where there are none there) but <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span> argue that their analyses suggest that that is not so.</p>
<!-- % pinheiro & bates 2000 / p.76 -->
<!-- % snijders & boskers p.60 -->
<!-- % snijders & boskers p.89 -->
</section>
<section id="sec-dev-mixed-anova" class="level3" data-number="5.13.2">
<h3 data-number="5.13.2" class="anchored" data-anchor-id="sec-dev-mixed-anova"><span class="header-section-number">5.13.2</span> Comparing models of varying random effects but constant fixed effects</h3>
<p>As noted, it is recommended <span class="citation" data-cites="Pinheiro2000aa">(<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">Pinheiro &amp; Bates, 2000</a>)</span> that we compare models of varying random effects using Restricted Maximum Likelihood (REML) fitting. We might be comparing different models with different sets of random effects if we are in the process of working out whether our model should include random intercepts and random slopes, that is, model parameters accounting for random differences between subjects or between items in the average level of performance or in the slope of the fixed effects. I think it is sensible to build up model complexity in the random component so that we are working through a series of model comparisons, comparing more simple with more complex models where the more complex model includes the same terms as the simpler model but adds some more.</p>
<p>In analyzing the effect of frequency on log RT for the ML study data, we can examine whether the random effects of subjects or of items on intercepts are necessary. Then we can examine if we should take into account random effects of subjects on the slope of the fixed effect of frequency, in addition to the random effects on intercepts.</p>
<p>To begin with, we look at a simpler model. We can fit a model with just the fixed effects of intercept and frequency, and the random effects of participants or items on intercepts only. We exclude the <code>(LgSUBTLCD + ...|subjectID)</code> specification for the random effect of participants on the slope of the frequency <code>LgSUBTLCD</code> effect.</p>
<p>We use REML fitting, as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer.REML.si  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span> LgSUBTLCD <span class="sc">+</span> </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                                    </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>                                          (<span class="dv">1</span><span class="sc">|</span>subjectID) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>item_name),</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> ML.all.correct, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lmer.REML.si)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: logrt ~ LgSUBTLCD + (1 | subjectID) + (1 | item_name)
   Data: ML.all.correct

REML criterion at convergence: -9845.1

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.5339 -0.6375 -0.1567  0.4364  5.5851 

Random effects:
 Groups    Name        Variance  Std.Dev.
 item_name (Intercept) 0.0003204 0.01790 
 subjectID (Intercept) 0.0032650 0.05714 
 Residual              0.0085285 0.09235 
Number of obs: 5257, groups:  item_name, 160; subjectID, 34

Fixed effects:
             Estimate Std. Error t value
(Intercept)  2.887697   0.013253   217.9
LgSUBTLCD   -0.034390   0.002774   -12.4

Correlation of Fixed Effects:
          (Intr)
LgSUBTLCD -0.658</code></pre>
</div>
</div>
<p>Notice:</p>
<ul>
<li><code>REML = TRUE</code> is the only change to the code: it specifies the change in model fitting method.</li>
</ul>
<p>You can see, also, I changed the model name to <code>ML.all.correct.lmer.REML.si</code> to be able to distinguish the maximum likelihood from the restricted maximum likelihood model.</p>
<p>Following <span class="citation" data-cites="baayen2008">Baayen et al. (<a href="references.html#ref-baayen2008" role="doc-biblioref">2008a</a>)</span>, we can then run a series of models with just one random effect. Firstly, just the random effect of items on intercepts:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer.REML.i  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>       LgSUBTLCD <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>item_name),</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> ML.all.correct, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lmer.REML.i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: logrt ~ LgSUBTLCD + (1 | item_name)
   Data: ML.all.correct

REML criterion at convergence: -8337

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.7324 -0.6455 -0.1053  0.4944  4.8970 

Random effects:
 Groups    Name        Variance  Std.Dev.
 item_name (Intercept) 0.0002364 0.01537 
 Residual              0.0117640 0.10846 
Number of obs: 5257, groups:  item_name, 160

Fixed effects:
             Estimate Std. Error t value
(Intercept)  2.886765   0.009047  319.07
LgSUBTLCD   -0.034206   0.002811  -12.17

Correlation of Fixed Effects:
          (Intr)
LgSUBTLCD -0.977</code></pre>
</div>
</div>
<p>Secondly, just the random effect of subjects on intercepts:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer.REML.s  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>       LgSUBTLCD <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>subjectID),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> ML.all.correct, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lmer.REML.s)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: logrt ~ LgSUBTLCD + (1 | subjectID)
   Data: ML.all.correct

REML criterion at convergence: -9786.3

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.5843 -0.6443 -0.1589  0.4434  5.5266 

Random effects:
 Groups    Name        Variance Std.Dev.
 subjectID (Intercept) 0.003275 0.05723 
 Residual              0.008837 0.09401 
Number of obs: 5257, groups:  subjectID, 34

Fixed effects:
             Estimate Std. Error t value
(Intercept)  2.885751   0.011561  249.60
LgSUBTLCD   -0.033888   0.001897  -17.87

Correlation of Fixed Effects:
          (Intr)
LgSUBTLCD -0.517</code></pre>
</div>
</div>
<p>If we now run Likelihood Ratio Test comparisons of these models, we are effectively examining if one of the random effects can be dispensed with: if its inclusion makes no difference to the likelihood of the model then it is not needed. Is the random effect of subjects on intercepts justified?</p>
<ul>
<li>Compare models, first, with <code>ML.all.correct.lmer.REML.si</code> versus without <code>ML.all.correct.lmer.REML.i</code> the random effect of subjects on intercepts.</li>
<li>Then compare models with <code>ML.all.correct.lmer.REML.si</code> versus without <code>ML.all.correct.lmer.REML.s</code> the random effect of items on intercepts.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ML.all.correct.lmer.REML.si, ML.all.correct.lmer.REML.i, <span class="at">refit =</span> <span class="cn">FALSE</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ML.all.correct.lmer.REML.si, ML.all.correct.lmer.REML.s, <span class="at">refit =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We compare models using the <code>anova()</code> function. We can list as many models as we like for comparison.</p>
<p>Notice:</p>
<ul>
<li><code>anova()</code> does the model comparison, for the models named in the list.</li>
<li>We specify <code>refit = FALSE</code>.</li>
</ul>
<p>We specify <code>refit = FALSE</code> because otherwise R will compare ML fitted models. (The refitting otherwise occurs, by default, to stop users from trying to compare REML models varying in fixed effects.)</p>
<p><span class="citation" data-cites="Pinheiro2000aa">Pinheiro &amp; Bates (<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">2000</a>)</span> advised that if one is fitting models with random effects the estimates are more accurate if the models are fitted using Restricted Maximum Likelihood (REML). That is achieved in the <code>lmer()</code> function call by adding the argument <code>REML=TRUE</code>. <span class="citation" data-cites="Pinheiro2000aa">Pinheiro &amp; Bates (<a href="references.html#ref-Pinheiro2000aa" role="doc-biblioref">2000</a>)</span> (see, e.g., pp.82-) recommended that if you compare models with the same fixed effects but with varying random effects then the models should be fitted using Restricted Maximum Likelihood.</p>
<p>We can do this for the foregoing series of models but what you will notice is that when we run the <code>anova()</code> function call, without the<code>refit = FALSE</code> argument, we get the warning <code>refitting model(s) with ML (instead of REML)</code>. Why? R refits models, for the comparison, using ML <em>even if</em> we originally specified REML fitting. It does this to stop users from comparing REML-fitted models with different sets of fixed effects see, as discussed <a href="https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q4/021040.html">here</a>.</p>
<p>As Ben Bolker points out (<a href="http://stackoverflow.com/questions/22892063/do-i-need-to-set-refit-false-when-testing-for-random-effects-in-lmer-models-wi">in this discussion</a>), analyses of simulated data analyses suggest that it does not make much difference whether we use REML or ML when we are comparing models with the same fixed effects but varying random effects. But it does matter <em>very much</em> that we should fit models using ML when we are comparing models with the same random effects but <em>differing fixed effects</em>.</p>
<p>When we run the <code>anova()</code> function call, it can be seen that the random effects of subjects on intercepts is required.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ML.all.correct.lmer.REML.si, ML.all.correct.lmer.REML.i, <span class="at">refit =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: ML.all.correct
Models:
ML.all.correct.lmer.REML.i: logrt ~ LgSUBTLCD + (1 | item_name)
ML.all.correct.lmer.REML.si: logrt ~ LgSUBTLCD + (1 | subjectID) + (1 | item_name)
                            npar     AIC     BIC logLik deviance  Chisq Df
ML.all.correct.lmer.REML.i     4 -8329.0 -8302.7 4168.5  -8337.0          
ML.all.correct.lmer.REML.si    5 -9835.1 -9802.3 4922.6  -9845.1 1508.1  1
                            Pr(&gt;Chisq)    
ML.all.correct.lmer.REML.i                
ML.all.correct.lmer.REML.si  &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>If you look at the results of the model comparison then you should notice:</p>
<ol type="1">
<li>The <code>ML.all.correct.lmer.REML.si</code> model is more complex than the <code>ML.all.correct.lmer.REML.i</code> model.</li>
</ol>
<ul>
<li><code>ML.all.correct.lmer.REML.si</code> includes <code>LgSUBTLCD + (1 | subjectID) + (1 | item_name)</code></li>
<li><code>ML.all.correct.lmer.REML.i</code> includes <code>LgSUBTLCD + (1 | item_name)</code>.</li>
</ul>
<ol start="2" type="1">
<li>The more complex model <code>ML.all.correct.lmer.REML.si</code> has AIC (<code>-9835.1</code>) and BIC (<code>-9802.3</code>) numbers that are larger or more negative, and has a likelihood (<code>4922.6</code>) that is larger than the simpler model <code>ML.all.correct.lmer.REML.i</code> which has AIC (<code>-8329.0</code>), BIC (<code>-8302.7</code>) and likelihood (<code>4168.5</code>).</li>
</ol>
<ul>
<li>The <span class="math inline">\(\chi^2 = 1508.1\)</span> statistic, on <code>1 Df</code> has a p-value of <code>Pr(&gt;Chisq) &lt;2.2e-16</code>.</li>
</ul>
<p>You can say that the comparison of the model <code>ML.all.correct.lmer.REML.si</code> with the random effect of participants on intercepts versus the model <code>ML.all.correct.lmer.REML.i</code> without the random effect of participants on intercepts shows that the inclusion of the random effect of participants on intercepts is <em>warranted by a significant difference in model fit</em>. (I highlight here the language you can use in your reporting.)</p>
<p>The second model comparison shows that the random effects of items on intercepts is also justified.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ML.all.correct.lmer.REML.si, ML.all.correct.lmer.REML.s, <span class="at">refit =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: ML.all.correct
Models:
ML.all.correct.lmer.REML.s: logrt ~ LgSUBTLCD + (1 | subjectID)
ML.all.correct.lmer.REML.si: logrt ~ LgSUBTLCD + (1 | subjectID) + (1 | item_name)
                            npar     AIC     BIC logLik deviance  Chisq Df
ML.all.correct.lmer.REML.s     4 -9778.3 -9752.0 4893.2  -9786.3          
ML.all.correct.lmer.REML.si    5 -9835.1 -9802.3 4922.6  -9845.1 58.825  1
                            Pr(&gt;Chisq)    
ML.all.correct.lmer.REML.s                
ML.all.correct.lmer.REML.si  1.723e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>If you look at the results of the model comparison then you should notice:</p>
<ol type="1">
<li>The <code>ML.all.correct.lmer.REML.si</code> model is more complex than the <code>ML.all.correct.lmer.REML.s</code> model.</li>
</ol>
<ul>
<li><code>ML.all.correct.lmer.REML.si</code> includes <code>LgSUBTLCD + (1 | subjectID) + (1 | item_name)</code>.</li>
<li><code>ML.all.correct.lmer.REML.s</code> includes <code>LgSUBTLCD + (1 | subjectID)</code></li>
</ul>
<ol start="2" type="1">
<li>The more complex model <code>ML.all.correct.lmer.REML.si</code> has AIC (<code>-9835.1</code>) and BIC (<code>-9802.3</code>) numbers that are larger or more negative, and has a likelihood (<code>4922.6</code>) that is larger than the simpler model <code>ML.all.correct.lmer.REML.s</code> which has AIC (<code>-9778.3</code>) and BIC (<code>-9752.0</code>) and likelihood (<code>4893.2</code>).</li>
</ol>
<ul>
<li>The <span class="math inline">\(\chi^2 = 58.825\)</span> statistic, on <code>1 Df</code> has a p-value of <code>Pr(&gt;Chisq) 1.723e-14</code>.</li>
</ul>
<p>You can say that the comparison of a model <code>ML.all.correct.lmer.REML.si</code> with versus a model <code>ML.all.correct.lmer.REML.s</code> without the random effect of items on intercepts shows that the inclusion of the random effect of items on intercepts is warranted by a significant difference in model fit.</p>
<p>I would conclude that both random effects of subjects and items on intercepts are required.</p>
<p>We can draw this conclusion because the difference between the model including just the random effect of items on intercepts <code>anova-ML-all-correct-lmer-REML-i</code>, or the model including just the random effect of subjects on intercepts <code>anova-ML-all-correct-lmer-REML-s</code>, compared to the model including both the random effect of items on intercepts and of subjects on intercepts <code>anova-ML-all-correct-lmer-REML</code> is significant. This tells us that the absence of the term accounting for the random effect of subjects on intercepts is associated with a significant decrease in model fit to data, in model likelihood.</p>
</section>
<section id="sec-dev-mixed-evaluate-random-effects" class="level3" data-number="5.13.3">
<h3 data-number="5.13.3" class="anchored" data-anchor-id="sec-dev-mixed-evaluate-random-effects"><span class="header-section-number">5.13.3</span> Evaluating random effects of subjects or items on slopes</h3>
<p>We should next consider whether it is justified or warranted to include in our model a term capturing the random effect of participants in the slope of the frequency effect. We may hold or we may make theoretical assumptions that justify including this random effect. Some researchers might ask: does the inclusion of the random effect seem warranted by improved model fit to data?</p>
<p>I should acknowledge, here, that there is an on-going discussion over what random effects should be included in mixed-effects models (see <span class="citation" data-cites="meteyard2020a">Meteyard &amp; Davies (<a href="references.html#ref-meteyard2020a" role="doc-biblioref">2020</a>)</span> for an overview). The discussion can be seen from a number of different perspectives. Key articles include those published by <span class="citation" data-cites="Baayen2008">Baayen et al. (<a href="references.html#ref-Baayen2008" role="doc-biblioref">2008b</a>)</span>, <span class="citation" data-cites="bates2015parsimonious">Bates et al. (<a href="references.html#ref-bates2015parsimonious" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span> and <span class="citation" data-cites="matuschek2017">Matuschek et al. (<a href="references.html#ref-matuschek2017" role="doc-biblioref">2017</a>)</span>.</p>
<p>You could be advised that a mixed-effects model should include all random effects that make sense a priori, so, here, we are talking about the random effects of participants on intercepts and on the slopes of all fixed effects that are in your model (variances and covariances) as well as all the random effects of items on intercepts and on slopes. This is characterized as the <em>keep it maximal</em> approach, associated with <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span>, though the discussion in that article is more nuanced than this sounds.</p>
<p>Or, you could be advised that a mixed-effects model should only include those random effects that appear to be justified or warranted by their usefulness in accounting for the data. In practice, this may mean, you should include only those random effects that appear justified by improved model fit to data, as indicated by a model comparison <span class="citation" data-cites="bates2015parsimonious matuschek2017">(see e.g. <a href="references.html#ref-bates2015parsimonious" role="doc-biblioref">Bates et al., 2015</a>; <a href="references.html#ref-matuschek2017" role="doc-biblioref">Matuschek et al., 2017</a>)</span>.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>I think, in practice, that maximal models can run into convergence problems. This means that many researchers adopt an approach which you could call: <strong>Maximum justifiable</strong>.</p>
<ul>
<li>This involves fitting a model, including all the random effects that make sense,</li>
<li>that are justified by improved model fit to data (given a significance test, model comparison)</li>
<li>for a model that <em>actually converges</em>.</li>
</ul>
</div>
</div>
<p>At present, viewpoints in discussions around the specification of random effects are associated with arguments that, as <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span> discuss, more comprehensive models appear to control the Type I (false positive) error rate better, or that, as <span class="citation" data-cites="matuschek2017">Matuschek et al. (<a href="references.html#ref-matuschek2017" role="doc-biblioref">2017</a>)</span> argue, control over the risk of false positives may come at the cost of increasing the Type II (false negative) error rate).</p>
<p>I think that it would seem to be axiomatic that a researcher <em>should</em> seek to account for all the potential sources of variance – fixed effects or random effects – that may influence observed outcomes. In practice, however, you may have insufficient data or inadequate measures to enable you to fit a model that converges with all the random effects, or to enable you to fit a model that converges that can estimate what may, in fact, be very small random effects variances or covariances. This is why some researchers are moving to adopt <em>Bayesian</em> mixed-effects modeling methods, as discussed by the developmental Psychologist, Michael Frank, for example, <a href="https://babieslearninglanguage.blogspot.com/2018/02/mixed-effects-models-is-it-time-to-go.html">here</a>. And as exemplified by my work <a href="https://peerj.com/articles/9511/">here</a>.</p>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>This discussion raises a question.</p>
<ul>
<li>Random slopes of what?</li>
</ul>
</div>
</div>
<p>In general, and simplifying things a bit, if an effect is manipulated <em>within grouping units</em> then we should specify random effects terms that allow us to take into account random differences between groups (e.g, between participants, stimulus words, or classes) in intercepts or in the slopes of the effects of theoretical interest, the fixed effects. The language of <em>within-subjects</em> or <em>between-subjects</em> effects is common in statistical education in psychological science and, I guess, it is a legacy of the focus of that education on ANOVA. A nice explanation of the difference between <em>within-subjects</em> or <em>between-subjects</em> effects can be found in <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span>.</p>
<p>In short, if a participant provides responses data under multiple levels of an experimental condition, or in response to multiple levels of a predictor variable (e.g.&nbsp;a person responds to multiple words, with differing frequency levels) then we are going to estimate or test the effect of that condition or that variable as if the condition is manipulated <em>within-subjects</em> or as if the responses to the variable vary <em>within-subjects</em>. If and only if we are in this situation, we can draw a plot of the kind you see in <a href="#fig-no-vs-complete-vs-partial">Figure&nbsp;<span>5.6</span></a>: where we may be able to see the way that the slope of the effect of the variable differs between participants. (In contrast, for example, outside of longitudinal studies, we would identify age as a between-subjects rather than a within-subjects variable and, if you think about it, we could not draw a grid of plots like <a href="#fig-no-vs-complete-vs-partial">Figure&nbsp;<span>5.6</span></a> to examine how the slope of the age effect might differ between participants.) In this situation, we can and should (as <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span> argue) specify random effects terms to account for between-participant differences in the slopes of the fixed effect.</p>
<p>We can examine the utility of random effects by comparing models with the same fixed effects but with varying random effects. We can specify a fixed effect term <em>inside</em> the random effects part of the mixed-effects model code, as we saw in <a href="#sec-dev-mixed-lmer"><span>Section&nbsp;5.9.5</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer.REML.slopes  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span> LgSUBTLCD <span class="sc">+</span> </span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>                                           </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>                                                (LgSUBTLCD <span class="sc">+</span> <span class="dv">1</span><span class="sc">|</span>subjectID) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>item_name),</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> ML.all.correct, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Looking at the code:</p>
<ul>
<li>With <code>(LgSUBTLCD + 1 |subjectID)</code> we specify a random effect of subjects on intercepts and on the slope of the frequency effects.</li>
<li>We do not specify – it happens by default – the estimation of the covariance of random differences among subjects in intercepts and random differences among subjects in the slope of the frequency effect.</li>
</ul>
<p>And as before, we can use <code>anova()</code> to check whether the increase in model complexity associated with the addition of random slopes terms is justified by an increase in model fit to data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(ML.all.correct.lmer.REML.si, ML.all.correct.lmer.REML.slopes, <span class="at">refit =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data: ML.all.correct
Models:
ML.all.correct.lmer.REML.si: logrt ~ LgSUBTLCD + (1 | subjectID) + (1 | item_name)
ML.all.correct.lmer.REML.slopes: logrt ~ LgSUBTLCD + (LgSUBTLCD + 1 | subjectID) + (1 | item_name)
                                npar     AIC     BIC logLik deviance  Chisq Df
ML.all.correct.lmer.REML.si        5 -9835.1 -9802.3 4922.6  -9845.1          
ML.all.correct.lmer.REML.slopes    7 -9854.1 -9808.1 4934.0  -9868.1 22.934  2
                                Pr(&gt;Chisq)    
ML.all.correct.lmer.REML.si                   
ML.all.correct.lmer.REML.slopes  1.047e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Inspection of the results shows us that, here, adjusting the model to include random effects of subjects in the slopes of the fixed effect of word frequency <em>does</em> improve model fit to data. In this situationn, we can report that:</p>
<ul>
<li>The inclusion of the random effect is warranted by improved model fit to data (<span class="math inline">\(\chi^2 (1 df) = 22.9, p &lt; .001\)</span>)}</li>
</ul>
</section>
<section id="sec-dev-mixed-discussion-p-values" class="level3" data-number="5.13.4">
<h3 data-number="5.13.4" class="anchored" data-anchor-id="sec-dev-mixed-discussion-p-values"><span class="header-section-number">5.13.4</span> Effects estimates and <em>significance</em> or p-values</h3>
<p>If you look at the fixed effects summary, you can see that we do not get p-values by default. To calculate p-values, we need to count residual degrees of freedom. The authors of the <code>{lme4}</code> library that furnishes the <code>lmer()</code> function do not <span class="citation" data-cites="Baayen2008">(as e.g. <a href="references.html#ref-Baayen2008" role="doc-biblioref">Baayen et al., 2008b</a> discuss)</span> think that it is sensible to estimate the residual degrees of freedom for a model in terms of the number of observations. This is because the number of observations concerns one level of a multilevel dataset that might be structured with respect to some number of subjects, some number of items. This means that one cannot then accurately calculate p-values to go with the t-tests on the coefficients estimates; therefore they do not.</p>
<p>While this makes sense to me (see comments earlier on Bayesian methods), Psychologists will often need p-values. This is now relatively easy.</p>
<p>We can run mixed-effects models with p-values from significance tests on the estimates of the fixed effects coefficients using the <code>library(lmerTest)</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmerTest)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>ML.all.correct.lmer.REML.slopes  <span class="ot">&lt;-</span> <span class="fu">lmer</span>(logrt <span class="sc">~</span> LgSUBTLCD <span class="sc">+</span> </span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                                           </span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                                                (LgSUBTLCD <span class="sc">+</span> <span class="dv">1</span><span class="sc">|</span>subjectID) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>item_name),</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> ML.all.correct, <span class="at">REML =</span> <span class="cn">TRUE</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ML.all.correct.lmer.REML.slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear mixed model fit by REML. t-tests use Satterthwaite's method [
lmerModLmerTest]
Formula: logrt ~ LgSUBTLCD + (LgSUBTLCD + 1 | subjectID) + (1 | item_name)
   Data: ML.all.correct

REML criterion at convergence: -9868.1

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.6307 -0.6324 -0.1483  0.4340  5.6132 

Random effects:
 Groups    Name        Variance  Std.Dev. Corr 
 item_name (Intercept) 0.0003268 0.01808       
 subjectID (Intercept) 0.0054212 0.07363       
           LgSUBTLCD   0.0002005 0.01416  -0.63
 Residual              0.0084333 0.09183       
Number of obs: 5257, groups:  item_name, 160; subjectID, 34

Fixed effects:
             Estimate Std. Error        df t value Pr(&gt;|t|)    
(Intercept)  2.887997   0.015479 47.782839 186.577  &lt; 2e-16 ***
LgSUBTLCD   -0.034471   0.003693 60.338787  -9.333 2.59e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
          (Intr)
LgSUBTLCD -0.764</code></pre>
</div>
</div>
<p>Basically, the call to access the <code>lmerTest</code> library ensures that when we run the <code>lmer()</code> function we get a calculation of an approximation to the denominator degrees of freedom that enables the calculation of the p-value for the t-test for the fixed effects coefficient. An alternative, as I have noted (<a href="#sec-dev-mixed-LRT"><span>Section&nbsp;5.12.3</span></a>) is to compare models with versus without the effect of interest.</p>
<section id="exercises-1" class="level4" data-number="5.13.4.1">
<h4 data-number="5.13.4.1" class="anchored" data-anchor-id="exercises-1"><span class="header-section-number">5.13.4.1</span> Exercises</h4>
<p>It will be useful for you to examine model comparisons with a different set of models for the same data.</p>
<p>You could try to run a series of models in which the fixed effects variable is something different, for example, the effect of word <code>Length: or the effect of orthographic neighbourhood size</code>Ortho_N:.</p>
<p>I would consider the model comparisons in the sequence shown in the foregoing, one pair of models at a time, to keep it simple. When you look at the model comparison, ask: is the difference between the models a piece of complexity (an effect) whose inclusion in the more complex model is justified or warranted by improved model fit to data?</p>
</section>
</section>
</section>
<section id="sec-dev-mixed-reporting-results" class="level2" data-number="5.14">
<h2 data-number="5.14" class="anchored" data-anchor-id="sec-dev-mixed-reporting-results"><span class="header-section-number">5.14</span> Reporting results</h2>
<section id="sec-dev-mixed-reporting-comparisons" class="level3" data-number="5.14.1">
<h3 data-number="5.14.1" class="anchored" data-anchor-id="sec-dev-mixed-reporting-comparisons"><span class="header-section-number">5.14.1</span> Reporting comparisons of ML and REML models</h3>
<p>If you look at an example mixed-effects analysis report, like that presented in <span class="citation" data-cites="Davies2013b">Davies et al. (<a href="references.html#ref-Davies2013b" role="doc-biblioref">2013</a>)</span>, you can see a few features of the reporting:</p>
<ul>
<li>Because it was an exploratory study, I started by reporting the comparison of models varying in fixed effects.</li>
<li>I explain what predictors are included in each model.</li>
<li>I explain how I make decisions about which model to select.</li>
<li>I then go on to discuss the comparison of models varying in random effects.</li>
</ul>
<blockquote class="blockquote">
<p>We stepped through a series of models. Firstly, assuming the same random effects of subjects and items on intercepts, we compared models differing in fixed effects: a model (model 1) with just initialstress factors; a model (model 2) with initialstress factors plus linear effects due to the orthographic.form, frequency, semantic, and bigram.frequency factors; and lastly a model (model 3) with the same factors as model 2 but adding restricted cubic splines for the frequency and orthographic.form factors to examine the evidence for the presence of curvilinear effects of frequency and length (the orthographic.form factor loads heavily on length).</p>
</blockquote>
<p>Notice also that I try to standardize the language and structure of the paragraphs – that kind of repetition or rhythm helps the reader, I think, by making what is not repeated – the model specifications – more apparent. Your style may differ, however, and that’s alright.</p>
<blockquote class="blockquote">
<p>We evaluated whether the inclusion of random effects was necessary in the final model (model 3) using LRT comparisons between models with the same fixed effects structure but differing random effects. Here, following Pinheiro &amp; Bates (2000; see, also, Baayen, 2008), models were fitted using the REML=TRUE setting in lmer. We compared models that included: (i.) both random effects of subjects and items, as specified for model 3; (ii.) just the random effect of subjects; (iii.) just the random effect of items.</p>
</blockquote>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>I want you to notice something more, concerning the predictors included in each different model:</p>
<ul>
<li>I do not include predictors one at a time, I include predictors in sets.</li>
</ul>
</div>
</div>
<p>For the <span class="citation" data-cites="Davies2013b">Davies et al. (<a href="references.html#ref-Davies2013b" role="doc-biblioref">2013</a>)</span> data set, I include first phonetic coding variables then psycholinguistic variables. I include linear effects then additional terms allowing the effects to be curvilinear</p>
<p>Finally, you can see that I report model comparisons in terms of Likelihood Ratio Test comparisons, firstly, considering the basis for selecting one model out of the models varying in fixed effects:</p>
<blockquote class="blockquote">
<p>Comparing models 1 and 2, models with initialstress factors but differing in whether they did or did not include key psycholinguistic factors like orthographic.form, the LRT statistic was significant (<span class="math inline">\(\chi^2 = 1,007, 4 df, p = 2 * 10^-16\)</span>). Comparing models 2 and 3, i.e.&nbsp;models with initialstress and key psycholinguistic components but differing in whether they did or did not use restricted cubic splines to fit the orthographic.form and frequency effects, the LRT statistic was significant (<span class="math inline">\(\chi^2 = 23, 2 df, p = 1 * 10^-5\)</span>).</p>
</blockquote>
<p>Then I report the selection of models varying in random effects:</p>
<blockquote class="blockquote">
<p>We compared models that included: (i.) both random effects of subjects and items, as specified for model 3; (ii.) just the random effect of subjects; (iii.) just the random effect of items. The difference between models (i.) and (ii.) was significant (<span class="math inline">\(\chi^2 = 185, 1 df, p = 2 * 10^-16\)</span>) indicating inclusion of an item effect was justified. The difference between models (i.) and (iii.) was significant (<span class="math inline">\(\chi^2 = 17,388, 1 df, p = 2 * 10^-16\)</span>) indicating inclusion of a subject effect was justified.</p>
</blockquote>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>You should include in your results report:</p>
<ul>
<li>A summary of fixed effects – just like in linear models, with coefficient estimates, standard errors, t and p (if you use it).</li>
<li>Report random effects variance and covariance (if applicable).</li>
<li>In text, report likelihood comparisons.</li>
<li>I recommend presenting the final model summary in a table that is structured like a multiple regression model summary table showing the random and the fixed effects.</li>
</ul>
</div>
</div>
</section>
</section>
<section id="sec-dev-mixed-summary" class="level2" data-number="5.15">
<h2 data-number="5.15" class="anchored" data-anchor-id="sec-dev-mixed-summary"><span class="header-section-number">5.15</span> Summary</h2>
<p>We examined another example of data from a repeated measures design study, this time, from a study involving adults responding to the lexical decision task, the ML study dataset.</p>
<p>We explored in more depth why linear mixed-effects models are more effective than other kinds of models when we are analyzing data with multilevel or crossed random effects structure. We discussed the critical ideas: pooling, and shrinkage. And we looked at how mixed-effects models employ partial-pooling so as to be more effective than alternative approaches dependent on complete pooling or no pooling estimates.</p>
<p>Mixed-effects models work better because they use both information from the whole dataset and information about each group (item or participant). This ensures that model estimates take into account random differences but are regularized so that they are not dominated by less reliable group-level information.</p>
<p>We considered, briefly, how mixed-effects models are estimated.</p>
<p>Then we examined, in depth, how mixed-effects models are fitted, compared and evaluated. The model comparison approach was set out, and we looked at both practical steps and at some of the tricky questions that, in practice, psychologists are learning to deal with.</p>
<p>We discussed how to compare models with varying random or fixed effects. We focused, especially, on the comparison of models with varying random effects. Methods for model comparison, including the use of information criteria and the Likelihood Ratio Test, were considered.</p>
<p>We discussed p-values, questions about calculating them, and a simple method for getting them when we need to report significance tests.</p>
<p>We discussed how mixed-effects models should be reported.</p>
<section id="sec-dev-mixed-glossary-useful-functions" class="level3" data-number="5.15.1">
<h3 data-number="5.15.1" class="anchored" data-anchor-id="sec-dev-mixed-glossary-useful-functions"><span class="header-section-number">5.15.1</span> Glossary: useful functions</h3>
<p>We used two functions to fit and evaluate mixed-effects models.</p>
<ul>
<li><code>lmer()</code> to fit mixed-effects models</li>
<li><code>anova()</code> to compare two or more models using AIC, BIC and the Likelihood Ratio Test.</li>
<li>We used the <code>lmerTest</code> library to furnish significance tests for coefficient estimates of fixed effects.</li>
</ul>
</section>
</section>
<section id="sec-dev-mixed-recommended-reading" class="level2" data-number="5.16">
<h2 data-number="5.16" class="anchored" data-anchor-id="sec-dev-mixed-recommended-reading"><span class="header-section-number">5.16</span> Recommended reading</h2>
<p>The most influential papers, at present, for the practice of mixed-effects modeling in psychological science are those by <span class="citation" data-cites="Baayen2008">Baayen et al. (<a href="references.html#ref-Baayen2008" role="doc-biblioref">2008b</a>)</span>, <span class="citation" data-cites="bates2015parsimonious">Bates et al. (<a href="references.html#ref-bates2015parsimonious" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="Barr2013a">Barr et al. (<a href="references.html#ref-Barr2013a" role="doc-biblioref">2013</a>)</span> and <span class="citation" data-cites="matuschek2017">Matuschek et al. (<a href="references.html#ref-matuschek2017" role="doc-biblioref">2017</a>)</span>. Each of these papers makes critical points and, in my view, each is clearly written with a good use of examples grounded in the scenarios psychologists often encounter.</p>
<p>Broader concerns about how are approach modeling, and what we look for as scientists, are discussed in <span class="citation" data-cites="Burnham2004">Burnham (<a href="references.html#ref-Burnham2004" role="doc-biblioref">2004</a>)</span>, <span class="citation" data-cites="Gelman2007ga">Gelman &amp; Hill (<a href="references.html#ref-Gelman2007ga" role="doc-biblioref">2007</a>)</span> and <span class="citation" data-cites="gelman2017">Gelman &amp; Hennig (<a href="references.html#ref-gelman2017" role="doc-biblioref">2017</a>)</span>.</p>
<p>A <em>very</em> useful FAQ on the practicalities of working with mixed-effects models can be found <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html">here</a>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-Baayen2008" class="csl-entry" role="doc-biblioentry">
Baayen, R. H., Davidson, D. J., &amp; Bates, D. M. (2008b). Mixed-effects modeling with crossed random effects for subjects and items. <em>Journal of Memory and Language</em>, <em>59</em>(4), 390–412. <a href="https://doi.org/10.1016/j.jml.2007.12.005">https://doi.org/10.1016/j.jml.2007.12.005</a>
</div>
<div id="ref-baayen2008" class="csl-entry" role="doc-biblioentry">
Baayen, R. H., Davidson, D. J., &amp; Bates, D. M. (2008a). Mixed-effects modeling with crossed random effects for subjects and items. <em>Journal of Memory and Language</em>, <em>59</em>(4), 390–412. <a href="https://doi.org/10.1016/j.jml.2007.12.005">https://doi.org/10.1016/j.jml.2007.12.005</a>
</div>
<div id="ref-Balota2007" class="csl-entry" role="doc-biblioentry">
Balota, D. a., Yap, M. J., Cortese, M. J., Hutchison, K. a., Kessler, B., Loftis, B., Neely, J. H., Nelson, D. L., Simpson, G. B., &amp; Treiman, R. (2007). The english lexicon project. <em>Behavior Research Methods</em>, <em>39</em>(3), 445–459. <a href="https://doi.org/10.3758/BF03193014">https://doi.org/10.3758/BF03193014</a>
</div>
<div id="ref-Barr2013a" class="csl-entry" role="doc-biblioentry">
Barr, D. J., Levy, R., Scheepers, C., &amp; Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. <em>Journal of Memory and Language</em>, <em>68</em>, 255–278.
</div>
<div id="ref-bates2015parsimonious" class="csl-entry" role="doc-biblioentry">
Bates, D., Kliegl, R., Vasishth, S., &amp; Baayen, H. (2015). Parsimonious mixed models. <em>arXiv Preprint arXiv:1506.04967</em>.
</div>
<div id="ref-box1976" class="csl-entry" role="doc-biblioentry">
Box, G. E. P. (1976). Science and statistics. <em>Journal of the American Statistical Association</em>, <em>71</em>(356), 791–799. <a href="https://doi.org/10.2307/2286841">https://doi.org/10.2307/2286841</a>
</div>
<div id="ref-Brysbaert2009a" class="csl-entry" role="doc-biblioentry">
Brysbaert, M., &amp; New, B. (2009). Moving beyond kucera and francis: A critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for american english. <em>Behavior Research Methods</em>, <em>41</em>(4), 977–990. <a href="https://doi.org/10.3758/BRM.41.4.977">https://doi.org/10.3758/BRM.41.4.977</a>
</div>
<div id="ref-Burnham2004" class="csl-entry" role="doc-biblioentry">
Burnham, K. P. (2004). Multimodel inference: Understanding AIC and BIC in model selection. <em>Sociological Methods &amp; Research</em>, <em>33</em>(2), 261–304. <a href="https://doi.org/10.1177/0049124104268644">https://doi.org/10.1177/0049124104268644</a>
</div>
<div id="ref-clark1973" class="csl-entry" role="doc-biblioentry">
Clark, H. (Stanford. U. (1973). <em>Clark<span>_</span>1973<span>_</span>LanguageAsAFixedEffectFallacy.pdf</em>.
</div>
<div id="ref-Cohen2003c" class="csl-entry" role="doc-biblioentry">
Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied multiple regression/correlation analysis for the behavioural sciences (3rd. edition)</em>. Lawrence Erlbaum Associates.
</div>
<div id="ref-Davies2013b" class="csl-entry" role="doc-biblioentry">
Davies, R., Barbon, A., &amp; Cuetos, F. (2013). Lexical and semantic age-of-acquisition effects on word naming in spanish. <em>Memory and Cognition</em>, <em>41</em>(2), 297–311.
</div>
<div id="ref-Forster2003a" class="csl-entry" role="doc-biblioentry">
Forster, K. I., &amp; Forster, J. C. (2003). DMDX: A windows display program with millisecond accuracy. <em>Behavior Research Methods, Instruments, &amp; Computers</em>, <em>35</em>, 116–124.
</div>
<div id="ref-Gelman2015a" class="csl-entry" role="doc-biblioentry">
Gelman, a. (2015). The connection between varying treatment effects and the crisis of unreplicable research: A bayesian perspective. <em>Journal of Management</em>, <em>41</em>(2), 632–643. <a href="https://doi.org/10.1177/0149206314525208">https://doi.org/10.1177/0149206314525208</a>
</div>
<div id="ref-gelman2017" class="csl-entry" role="doc-biblioentry">
Gelman, A., &amp; Hennig, C. (2017). Beyond subjective and objective in statistics. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, <em>180</em>(4), 967–1033.
</div>
<div id="ref-Gelman2007ga" class="csl-entry" role="doc-biblioentry">
Gelman, A., &amp; Hill, J. (2007). <em>Data analysis using regression and multilevel/hierarchical models</em>. Cambridge University Press.
</div>
<div id="ref-howell2016fundamental" class="csl-entry" role="doc-biblioentry">
Howell, D. C. (2016). <em>Fundamental statistics for the behavioral sciences</em>. Cengage learning.
</div>
<div id="ref-judd2012" class="csl-entry" role="doc-biblioentry">
Judd, C. M., Westfall, J., &amp; Kenny, D. A. (2012). <em>Treating stimuli as a random factor in social psychology : A new and comprehensive solution to a pervasive but largely ignored problem</em>. <em>103</em>(1), 54–69. <a href="https://doi.org/10.1037/a0028347">https://doi.org/10.1037/a0028347</a>
</div>
<div id="ref-Masterson2007c" class="csl-entry" role="doc-biblioentry">
Masterson, J., &amp; Hayes, M. (2007). Development and data for UK versions of an author and title recognition test for adults. <em>Journal of Research in Reading</em>, <em>30</em>, 212–219.
</div>
<div id="ref-matuschek2017" class="csl-entry" role="doc-biblioentry">
Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., &amp; Bates, D. (2017). Balancing type i error and power in linear mixed models. <em>Journal of Memory and Language</em>, <em>94</em>, 305–315. <a href="https://doi.org/10.1016/j.jml.2017.01.001">https://doi.org/10.1016/j.jml.2017.01.001</a>
</div>
<div id="ref-mcelreath2020" class="csl-entry" role="doc-biblioentry">
McElreath, R. (2020). <em>: A bayesian course with examples in r and STAN</em> (2nd ed.). Chapman; Hall/CRC. <a href="https://doi.org/10.1201/9780429029608">https://doi.org/10.1201/9780429029608</a>
</div>
<div id="ref-meteyard2020a" class="csl-entry" role="doc-biblioentry">
Meteyard, L., &amp; Davies, R. A. I. (2020). Best practice guidance for linear mixed-effects models in psychological science. <em>Journal of Memory and Language</em>, <em>112</em>, 104092. <a href="https://doi.org/10.1016/j.jml.2020.104092">https://doi.org/10.1016/j.jml.2020.104092</a>
</div>
<div id="ref-Pinheiro2000aa" class="csl-entry" role="doc-biblioentry">
Pinheiro, J. C., &amp; Bates, D. M. (2000). <em>Mixed-effects models in s and s-plus (statistics and computing)</em>. Springer.
</div>
<div id="ref-raaijmakers1999" class="csl-entry" role="doc-biblioentry">
Raaijmakers, J. G. W., Schrijnemakers, J. M. C., &amp; Gremmen, F. (1999). How to deal with <span>"</span>the language-as-fixed-effect fallacy<span>"</span>: Common misconceptions and alternative solutions. <em>Journal of Memory and Language</em>, <em>41</em>(3), 416–426. <a href="https://doi.org/10.1006/jmla.1999.2650">https://doi.org/10.1006/jmla.1999.2650</a>
</div>
<div id="ref-Snijders2004a" class="csl-entry" role="doc-biblioentry">
Snijders, T. A. B., &amp; Bosker, R. J. (2004). <em>Multilevel analysis: An introduction to basic and advanced multilevel modeling</em>. Sage Publications Ltd.
</div>
<div id="ref-steegen2016" class="csl-entry" role="doc-biblioentry">
Steegen, S., Tuerlinckx, F., Gelman, A., &amp; Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. <em>Perspectives on Psychological Science</em>, <em>11</em>(5), 702–712.
</div>
<div id="ref-torgesen1999towre" class="csl-entry" role="doc-biblioentry">
Torgesen, J. K., Rashotte, C. A., &amp; Wagner, R. K. (1999). <em>TOWRE: Test of word reading efficiency</em>. Pro-ed Austin, TX.
</div>
<div id="ref-Yarkoni2008b" class="csl-entry" role="doc-biblioentry">
Yarkoni, T., Balota, D., &amp; Yap, M. (2008). Moving beyond coltheart’s n: A new measure of orthographic similarity. <em>Psychonomic Bulletin &amp; Review</em>, <em>15</em>(5), 971–979. <a href="https://doi.org/10.3758/PBR.15.5.971">https://doi.org/10.3758/PBR.15.5.971</a>
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Box also says: “It is inappropriate to be concerned about mice when there are tigers about.” <span class="citation" data-cites="box1976">(<a href="references.html#ref-box1976" role="doc-biblioref">Box, 1976</a>)</span> That is too wise a saying to leave out.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-mixed.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction to linear mixed-effects models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-glmm.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to Generalized Linear Mixed-effects Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>